{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dPfVKv2adDm"
   },
   "source": [
    "# Машинное обучение, DS-поток\n",
    "## Задание 1.11\n",
    "\n",
    "\n",
    "**Правила:**\n",
    "\n",
    "* Выполненную работу нужно отправить телеграм-боту `@miptstats_ad21_bot`.\n",
    "* Дедлайны см. в боте. После дедлайна работы не принимаются кроме случаев наличия уважительной причины.\n",
    "* Прислать нужно ноутбук в формате `ipynb`.\n",
    "* Решения, размещенные на каких-либо интернет-ресурсах не принимаются. Публикация решения может быть приравнена к предоставлении возможности списать.\n",
    "* Для выполнения задания используйте этот ноутбук в качестве основы, ничего не удаляя из него.\n",
    "\n",
    "---\n",
    "\n",
    "## Генерация текстов с использованием RNN.\n",
    "\n",
    "**Части задания.** \n",
    "\n",
    "* Написание модели, лосса и кода для обучения (7 баллов)\n",
    "\n",
    "* Реализация жадного алгоритма генерации (3 балла)\n",
    "\n",
    "* Одно из:\n",
    "\n",
    "  * Реализация Top k sampling (2 балла)\n",
    "\n",
    "  * Реализация Beam-search (6 баллов)\n",
    "\n",
    "\n",
    "В данном задании вы будете генерировать тексты на основании высказываний [Ницше](https://ru.wikipedia.org/wiki/Ницше,_Фридрих) при помощи рекуррентных сетей. \n",
    "Модель будет основываться на токенах — словах или более продвинутых способах работы с текстом.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Xt4DweWs4RO"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qED98FUNs_ej"
   },
   "source": [
    "Скачиваем данные. Корпус состоит из высказываний Ницше, разделеных переносом строки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 909,
     "status": "ok",
     "timestamp": 1650661991031,
     "user": {
      "displayName": "Владимир Никитин",
      "userId": "13111598681369803225"
     },
     "user_tz": -180
    },
    "id": "ZxtkObdPtEd1",
    "outputId": "3b02d945-6788-477a-f33a-a07f196adabc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-22 21:13:10--  https://docs.google.com/uc?export=download&id=1QefWGfvcn0CXzmd42ySFTkwd1shHTUA3\n",
      "Resolving docs.google.com (docs.google.com)... 173.194.193.101, 173.194.193.100, 173.194.193.138, ...\n",
      "Connecting to docs.google.com (docs.google.com)|173.194.193.101|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://doc-04-4c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/25sl2mghkp2va7sqatqf9c6e7u6h76f4/1650661950000/14359032242157329066/*/1QefWGfvcn0CXzmd42ySFTkwd1shHTUA3?e=download [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2022-04-22 21:13:11--  https://doc-04-4c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/25sl2mghkp2va7sqatqf9c6e7u6h76f4/1650661950000/14359032242157329066/*/1QefWGfvcn0CXzmd42ySFTkwd1shHTUA3?e=download\n",
      "Resolving doc-04-4c-docs.googleusercontent.com (doc-04-4c-docs.googleusercontent.com)... 173.194.195.132, 2607:f8b0:4001:c11::84\n",
      "Connecting to doc-04-4c-docs.googleusercontent.com (doc-04-4c-docs.googleusercontent.com)|173.194.195.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 600901 (587K) [text/plain]\n",
      "Saving to: ‘uc?export=download&id=1QefWGfvcn0CXzmd42ySFTkwd1shHTUA3’\n",
      "\n",
      "uc?export=download& 100%[===================>] 586.82K  --.-KB/s    in 0.007s  \n",
      "\n",
      "2022-04-22 21:13:11 (86.2 MB/s) - ‘uc?export=download&id=1QefWGfvcn0CXzmd42ySFTkwd1shHTUA3’ saved [600901/600901]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1QefWGfvcn0CXzmd42ySFTkwd1shHTUA3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1650661991032,
     "user": {
      "displayName": "Владимир Никитин",
      "userId": "13111598681369803225"
     },
     "user_tz": -180
    },
    "id": "dZ9QYAI7XFHX",
    "outputId": "60b08dd1-935c-479c-8282-926d791b6882"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFACE\n",
      "\n",
      "\n",
      "SUPPOSING that Truth is a woman--what then? Is there not ground\n",
      "for suspecting that all philosophers, in so far as they have been\n",
      "dogmatists, have failed to understand women--that the terrible\n",
      "seriousness and clumsy importunity with which they have usually paid\n",
      "their addresses to Truth, have been unskilled and unseemly methods for\n",
      "winning a woman? Certainly she has never allowed herself to be won; and\n",
      "at present every kind of dogma stands with sad and discouraged mien--IF,\n"
     ]
    }
   ],
   "source": [
    "!head nietzsche.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEWI-vHktPSZ"
   },
   "source": [
    "Посмотрим сколько уникальных слов есть в корпусе.\n",
    "Также поставим каждому слову (токену) в соответствие число, чтобы далее работать с числами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 624,
     "status": "ok",
     "timestamp": 1650661994790,
     "user": {
      "displayName": "Владимир Никитин",
      "userId": "13111598681369803225"
     },
     "user_tz": -180
    },
    "id": "3qr1njwhtHzz",
    "outputId": "7ca4cec8-a1b0-4d3f-9082-36265e9fe522"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tokens: 11393\n"
     ]
    }
   ],
   "source": [
    "with io.open('./nietzsche.txt', encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "\n",
    "tokenizer = TweetTokenizer()\n",
    "tokens = list(set(tokenizer.tokenize(text)))\n",
    "print('total tokens:', len(tokens))\n",
    "\n",
    "token_indices = {c: i for i, c in enumerate(tokens)}\n",
    "indices_token = {i: c for i, c in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lnbPfiSn-e4-"
   },
   "source": [
    "11393 уникальных слов — это относительно много, так как придется на каждом шаге решать задачу классификации на 11393 класса. А брать софтмакс от вектора такой большой размерности затруднительно. Поэтому имеется несколько вариантов: простой (1), очень простой (2) и современный (3) .\n",
    "\n",
    "1. Отбросить редко встречающиеся слова (токены) и заменить их все на токен \\<UNK\\>. \n",
    "\n",
    "2. Использовать в качестве токенов символы, а не слова. Такую модель мы использовали на семинаре для генерации имён.\n",
    "Этот подход имеет явный недостаток — модели, обучаемой на отдельных символах, гораздо сложнее выучить соотношения между буквами в каждом отдельном слове. Из-за этого может возникнуть ситуация, при которой значительная часть слов, сгенерированных моделью, не будут являться словами языка, на котором написаны входные тексты.\n",
    "\n",
    "3. Использовать [Byte Pair Encoding](https://arxiv.org/pdf/1508.07909.pdf). [Одна из опен-сорсных реализаций](https://github.com/VKCOM/YouTokenToMe) от ребят из VK.\n",
    "\n",
    "Существуют также подходы для аппроксимации softmax, такие как иерархический софтмакс и negative sampling.\n",
    "\n",
    "Разберём, как работает BPE на примере строки `aaabdaaabac`.\n",
    "Пара `aa` встречается чаще всего, поэтому она будет заменяется символом `Z`, который не используется в данных, получается строка `ZabdZabac`.\n",
    "Далее процесс повторяется для пары `ab`, которая заменяется на символ `Y`. Теперь строка имеет вид `ZYdZYac`, причем единственная оставшаяся пара исходных символов встречается только один раз. На этом кодировку можно остановить или же продолжать рекурсивно заменив `ZY` на `X`: `XdXac`. Полученную строку нельзя продолжать сжимать, поскольку не существует пары символов, встречающихся более одного раза. Для декодирования нужно выполнить замены в обратном порядке.\n",
    "\n",
    "Если же мы будем проделывать эту процедуру не над маленькой строкой, а над большим датасетом, то мы найдем часто встречающиеся n-gram-ы из символов в датасете. Полученные замены будем использовать как новые токены и представлять каждое слово как последовательность таких токенов.\n",
    "В данном случае получится, что частые слова скорей всего будут представлены лишь одним токеном, равным самому слову. А редкие слова разобъются на последовательность токенов, являющихся частыми.\n",
    "\n",
    "\n",
    "![](https://docs.google.com/uc?export=download&id=1bD-VA4EWfmMsqFT4ufIhCMDh2fKlP_rC)\n",
    "\n",
    "Метод BPE является некоторой золотой серединой между character-based и word-based подходами.\n",
    "[`YouTokenToMe`](https://github.com/VKCOM/YouTokenToMe) — одна из опен-сорсных реализаций от разработчиков из VK. \n",
    "Также можно посмотреть [статью](https://arxiv.org/abs/1910.13267) студента ФИВТа с конференции ACL 2020 по bpe-dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E41erLUtM6ts"
   },
   "source": [
    "Ставим библиотеку, речь о которой шла выше:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4532,
     "status": "ok",
     "timestamp": 1650662003115,
     "user": {
      "displayName": "Владимир Никитин",
      "userId": "13111598681369803225"
     },
     "user_tz": -180
    },
    "id": "ByZPyRZevQnq",
    "outputId": "10fb60f3-9776-4fb3-bdc2-e834b8c1bf71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtokentome\n",
      "  Downloading youtokentome-1.0.6-cp37-cp37m-manylinux2010_x86_64.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 5.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from youtokentome) (7.1.2)\n",
      "Installing collected packages: youtokentome\n",
      "Successfully installed youtokentome-1.0.6\n"
     ]
    }
   ],
   "source": [
    "! pip install youtokentome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1Lh_7mjM9fz"
   },
   "source": [
    "Создаем BPE-модель, которую обучим на наших токенах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xDWt7rAHvxZa"
   },
   "outputs": [],
   "source": [
    "import youtokentome as yttm\n",
    "\n",
    "# Зададим желаемый размер словаря после BPE.\n",
    "# BPE перестанет объединять символы и токены в тот момент, \n",
    "# когда текущее количество токенов >= vocab_size\n",
    "vocab_size = 1000\n",
    "\n",
    "def get_bpe(tokens, vocab_size=vocab_size):\n",
    "    \"\"\" \n",
    "    Возвращает токенизатор BPE, обученный на токенах.\n",
    "    Параметры.\n",
    "    1) tokens - токены,\n",
    "    2) vocab_size - количество уникальных токенов в итоговом словаре.\n",
    "    \"\"\"\n",
    "\n",
    "    with open('tmp.json', 'w') as file_:\n",
    "        for token in tokens:\n",
    "            print(token, file=file_)\n",
    "\n",
    "    yttm.BPE.train('tmp.json', vocab_size=vocab_size, model=\"bpe.model\")\n",
    "    os.remove('tmp.json')\n",
    "\n",
    "    return yttm.BPE(model=\"bpe.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5jhKmf2wSHA"
   },
   "outputs": [],
   "source": [
    "bpe = get_bpe(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Pu0MlfyNCZD"
   },
   "source": [
    "Пример работы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1650662019428,
     "user": {
      "displayName": "Владимир Никитин",
      "userId": "13111598681369803225"
     },
     "user_tz": -180
    },
    "id": "9PBmpg7zwf66",
    "outputId": "1318350b-335c-4446-8d73-50bd346e06f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  supposing that truth is a woman--what then? is there not ground \n",
      "\n",
      "BPE decoded:  <BOS> ▁sup pos ing ▁th at ▁truth ▁is ▁a ▁w oman --what ▁th en ? ▁is ▁there ▁not ▁gr ound <EOS> \n",
      "\n",
      "BPE encoded:  [2, 597, 268, 69, 153, 79, 871, 772, 86, 101, 595, 712, 153, 64, 55, 772, 612, 763, 228, 267, 3]\n"
     ]
    }
   ],
   "source": [
    "example = text.split('\\n')[3]\n",
    "\n",
    "print('Original: ', example, '\\n')\n",
    "print('BPE decoded: ', *bpe.encode(\n",
    "    example, output_type=yttm.OutputType.SUBWORD, bos=True, eos=True\n",
    "    ), '\\n', sep=' ')\n",
    "print('BPE encoded: ', bpe.encode(\n",
    "    example, output_type=yttm.OutputType.ID, bos=True, eos=True\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6e9oGs4adDo"
   },
   "source": [
    "Напишите нейронную сеть, использующую RNN, которая должна обучиться на *каждом шаге* предсказывать следующий токен. Для этого вам понадобится к каждому скрытому состоянию RNN применить некоторую классификационную нейронную сеть. На каждом этапе времени такая сеть будет пытаться предсказать следующий токен. На каждом этапе времени должно получиться свое предсказание вероятности для следующего токена. После этого необходимо усреднить лосс по полученным предсказаниям.\n",
    "\n",
    "**Замечания** <br>\n",
    "1). Проследите, что вы действительно предсказываете следующий символ, а не текущий. Для этого можно поступить следующим образом.\n",
    "\n",
    "Пусть на вход приходит последовательность $x_1, x_2, ..., x_{n}$. Требуется на каждом этапе времени $t$ по символам $x_1, ..., x_{t - 1}$ предсказывать символ $x_t$. Для этого на вход нужно подать последовательность \\<BOS\\>, $x_1, x_2..., x_{n}$ и в качестве таргетов взять последовательность $x_1, x_2, ..., x_{n}, $ \\<EOS\\>. В данном случае \\<BOS\\> (begin of sentence), \\<EOS\\>(end of sentence) — специальные символы начала и конца предложения (любые новые символы, которых нет в словаре). \n",
    "\n",
    "2). При обучении вы подаете на вход истинные токены и предсказываете следующий токен, но при тестировании истинных токенов нет. Поэтому при тестировании стоит поступить следующим образом.\n",
    "* Подать на вход \\<BOS\\>, применить рекуррентную ячейку и предсказать вероятности быть следующим символом для каждого токена из словаря. \n",
    "* Найти токен с максимальной вероятностью. Обозначим его $x_1$. \n",
    "* Подать символ $x_1$ на вход рекуррентной ячейке и предсказать вероятности для следующих символов. \n",
    "* И так далее. Генерация продолжается до тех пор, пока не был предсказан токен \\<EOS\\> или мы не достигли нужной `length_to_predict` длины сгенерированного текста, где `length_to_predict` — число, заданное заранее.\n",
    "\n",
    "Заметим, что при наличии начальной последовательности $x_1, .., x_k$, которую нужно продолжить, сначала на вход нужно подавать истинные символы, а затем, когда истинные закончатся, подавать предсказанные символы. То есть в этом случае мы подаем \\<BOS\\>, $x_1, .., x_k$ на вход и уже потом начинаем генерацию.\n",
    "\n",
    "На рисунке ниже можно увидеть пример такой сети. При обучении на вход подаются истинные токены. На этапе времени $t - 1$ предсказываются вероятности $\\widehat{y}_{i}$ быть следующим ($i$-ым) токеном для всех токенов из словаря. \n",
    "В качестве лосса в данном случае рассматривается функция $\\frac{1}{n} \\sum\\limits_{i=1}^{n} H(y_i, \\widehat{y}_i)$, где $H(\\mathsf{P}, \\mathsf{Q})$ — кросс-энтропия, а $y^i$ — вырожденное распределение, соответствующее истинному индексу $i$-ого токена.\n",
    "\n",
    "На этапе применения на вход рекуррентной ячейке подается не настоящий токен, а тот токен, который имел наибольшую вероятность быть следующим на предыдущем шаге."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMgb5Xl2adDp"
   },
   "source": [
    "![img](https://i.ibb.co/BnftCLh/Screenshot-2019-05-03-at-21-45-01.png)\n",
    "\n",
    "![imh](https://i.ibb.co/rwHyYsK/Screenshot-2019-05-03-at-21-44-53.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0F8odJpoCXK5"
   },
   "source": [
    "Получим таргеты для обучения. Для этого к каждой строке, т.е. последовательности bpe-токенов добавим токен '\\<EOS\\>'. Также, сделаем так, чтобы все строки были одной и той же длины, добавив паддинг из символов '\\<PAD\\>'.\n",
    "\n",
    "Таким образом, строка $x_1, x_2, ..., x_{8}$ должна преобразиться в $x_1, x_2, ..., x_{8}$, \\<EOS\\>, \\<PAD\\>, \\<PAD\\>, \\<PAD\\> в случае если мы хотим, чтобы длина всех строк была 12.\n",
    "\n",
    "После данных преобразований переведите полученные строки в последовательность чисел, с которыми уже далее будет работать модель. Для этого можно использовать метод `bpe.subword_to_id`\n",
    "\n",
    "Для этого сначала найдем максимальную длину строки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1650662024974,
     "user": {
      "displayName": "Владимир Никитин",
      "userId": "13111598681369803225"
     },
     "user_tz": -180
    },
    "id": "r5MymVXTD-lB",
    "outputId": "dd36b718-3483-4b0a-e10c-8facc5a83b0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальная длина строки: 40\n"
     ]
    }
   ],
   "source": [
    "length = []\n",
    "\n",
    "for string in text.split('\\n'):\n",
    "    bpe_string = bpe.encode(string, output_type=yttm.OutputType.SUBWORD, bos=False, eos=False)\n",
    "    if len(bpe_string) > 0:\n",
    "      length.append(len(bpe_string))\n",
    "print(\"Максимальная длина строки:\", np.max(length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGjj7L6OF24F"
   },
   "source": [
    "Посчитаем таргеты. Учитывайте, что так как мы добавляем символ \\<EOS\\>, то полученная длина строки должна быть на 1 больше.\n",
    "\n",
    "*Замечание* \n",
    "\n",
    "После разбиения текста `text` на строки стоит проверить, что все строки имеют ненулевую длину. Строки нулевой длины нужно выкинуть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 417,
     "status": "ok",
     "timestamp": 1650662026351,
     "user": {
      "displayName": "Владимир Никитин",
      "userId": "13111598681369803225"
     },
     "user_tz": -180
    },
    "id": "NeXRQPrTD7kK",
    "outputId": "73a04bab-9a86-4cc6-8bde-380460b938a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9037, 41)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LENGTH = np.max(length) + 1\n",
    "target = []\n",
    "\n",
    "for string in text.split('\\n'):\n",
    "    bpe_string = bpe.encode(string, output_type=yttm.OutputType.ID, bos=False, eos=True)\n",
    "    if len(bpe_string) > 1:\n",
    "      bpe_string+=[bpe.subword_to_id('<PAD>')]*(MAX_LENGTH-len(bpe_string))\n",
    "      target.append(bpe_string)\n",
    "target=np.array(target)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sr29VFWBELHv"
   },
   "source": [
    "Получим то, что подается на вход нейросети. Из таргет-строк получите строки тех же длин, которые начинаются с символа \\<BOS\\> и будут без последнего символа таргет-строки. Полученные строки также должны состоять из чисел, как и ранее посчитанные таргет-строки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XTDInid-DYoN"
   },
   "outputs": [],
   "source": [
    "target_input=target.copy()\n",
    "target_input=np.roll(target_input, 1, axis=1)\n",
    "target_input[:,0]=bpe.subword_to_id('<BOS>')\n",
    "index_EOS=np.where(target_input==bpe.subword_to_id('<EOS>'))\n",
    "target_input[index_EOS]=bpe.subword_to_id('<PAD>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbCUWrJGAyir"
   },
   "outputs": [],
   "source": [
    "pad_idx=bpe.subword_to_id('<PAD>')\n",
    "num_tokens=vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "th1Dp1Q05ZWk"
   },
   "source": [
    "Разбейте полученные данные на обучение и валидацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DqFLzfKm5z0b"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(target_input, target, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFc9wY_Z5ip2"
   },
   "source": [
    "Приступим к написанию модели. Ваша модель должна состоять из эмбеддинг слоя, рекуррентного слоя (по желанию, возможно несколько слоев) и линейного слоя, который будет применяться к каждому скрытому состоянию рекуррентного слоя.\n",
    "\n",
    "В качестве рекуррентного слоя (слоев) лучше использовать `nn.GRU`, `nn.GRUCell`, `nn.LSTM` или `nn.LSTMCell` по вашему желанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G4qk8NGPCNIZ"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "  #сделаем модель на основе nn.GRU, должно дать более хороший результат\n",
    "  #так как у нас не так много данных\n",
    "  def __init__(self, num_tokens=num_tokens, emb_size=1000, hidden_size =500):\n",
    "    super(Model, self).__init__()\n",
    "    self.emb = nn.Embedding(vocab_size, emb_size)\n",
    "    self.gru = nn.GRU(emb_size, hidden_size , batch_first=True, dropout=0.1)\n",
    "    self.hid_to_logits = nn.Linear(hidden_size , num_tokens)\n",
    "\n",
    "  def forward(self, x,h0=None):\n",
    "    emb = self.emb(x)\n",
    "    \n",
    "    if h0 is not None:\n",
    "      output, h = self.gru(emb,h0)\n",
    "    else:\n",
    "      output, h = self.gru(emb)\n",
    "\n",
    "    next_logits = self.hid_to_logits(output)\n",
    "\n",
    "    # next_logits.size = [batch_size, max_name_len, num_tokens]\n",
    "    next_logp = F.log_softmax(next_logits, dim=-1)\n",
    "    return next_logp,h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fruPdins7TPb"
   },
   "source": [
    "Напишите функцию вычисления лосса. \n",
    "\n",
    "**Замечание.**\n",
    "\n",
    "Добавленные при помощи паддинга символы не должны оказывать влияния на лосс. То есть по позициям, где истинный символ является специальным символом для паддинга, при вычислении лосса не нужно обращать внимания на предсказания. В противном случае нейронная сеть может научиться всегда предсказывать этот специальный символ из-за того, что он часто встречается. \n",
    "\n",
    "Однако, лосс по символу '\\<EOS\\>' должен быть посчитан и добавлен к финальному лоссу.\n",
    "\n",
    "Например, можно посчитать лосс следующим образом:\n",
    "\n",
    "`criterion = nn.CrossEntropyLoss(ignore_index=pad_ix, size_average=True)`\n",
    "\n",
    "`criterion(logits, y_batch)`\n",
    "\n",
    "вместо\n",
    "\n",
    "`F.cross_entropy(logits, y_batch)`\n",
    "\n",
    "Здесь `pad_ix` — число, которое мы поставили в соответствие специальному символу для паддинга ранее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmwkUv3vRwmB"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00nujYac86hK"
   },
   "outputs": [],
   "source": [
    "def compute_loss(model, X_batch, y_batch):\n",
    "    criterion = nn.NLLLoss(ignore_index=pad_idx, size_average=True)\n",
    "    X_batch = torch.tensor(X_batch, dtype=torch.int64).to(device)\n",
    "    y_batch = torch.tensor(y_batch, dtype=torch.int64).to(device)\n",
    "    \n",
    "    # Логиты, полученные моделью\n",
    "    logits,_= model(X_batch)\n",
    "    #print(logits.shape,logits.contiguous().view(-1, num_tokens).shape,y_batch.shape)\n",
    "    # Лосс на валидации\n",
    "    loss = criterion(logits.contiguous().view(-1, num_tokens),\n",
    "                 y_batch.long().contiguous().view(-1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ToyX4Up6DbA"
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(model, X_batch, y_batch):\n",
    "    X_batch = torch.tensor(X_batch, dtype=torch.int64).to(device)\n",
    "    \n",
    "    # Логиты, полученные моделью\n",
    "    logits,_ = model(X_batch)\n",
    "    logits=np.argmax(logits.cpu().detach().numpy(),axis=2)\n",
    "    \n",
    "    acc=accuracy_score(y_batch.reshape(-1),logits.reshape(-1))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFviN_QJ7cjZ"
   },
   "source": [
    "Напишем функцию генерации батчей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2KbDaPXK7c-Z"
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(X, y, batch_size, shuffle=True):\n",
    "    \"\"\" Генератор случайных батчей \"\"\"\n",
    "\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(np.arange(len(X)))\n",
    "    else:\n",
    "        indices = np.arange(len(X))\n",
    "        \n",
    "    for start in range(0, len(indices), batch_size):\n",
    "        ix = indices[start: start + batch_size]\n",
    "        yield X[ix], y[ix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diOfP7gn7NTq"
   },
   "source": [
    "Инициализируем модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8711,
     "status": "ok",
     "timestamp": 1650662055136,
     "user": {
      "displayName": "Владимир Никитин",
      "userId": "13111598681369803225"
     },
     "user_tz": -180
    },
    "id": "jGborO_QLdDx",
    "outputId": "92c80a2b-3d56-418a-8883-2b09ff43ec19"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yak0RMMz7lnN"
   },
   "source": [
    "Обучение. Это может занять некоторое время. Постройте также график кривой обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "executionInfo": {
     "elapsed": 207709,
     "status": "ok",
     "timestamp": 1650647551022,
     "user": {
      "displayName": "Владимир Никитин",
      "userId": "13111598681369803225"
     },
     "user_tz": -180
    },
    "id": "AHML-rJ1Kj44",
    "outputId": "85f3d755-f515-43bc-970e-47a6c0eb7151"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIUAAAGuCAYAAAAOH7b/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXxdd33n/9ddtO+bbdmy5f14i+PY2SArhCUsIUDYW2CG0kJom3aA36PttNOWmdJhYNrfTMteKDu0hJKQ0pAFQshCQhZncZz4eJdkW45l7bt0de/8ITk4wYklW9KR7n09Hw89dJejc99fx849+tzv9/ONZTIZJEmSJEmSlFviUQeQJEmSJEnS7LMoJEmSJEmSlIMsCkmSJEmSJOUgi0KSJEmSJEk5yKKQJEmSJElSDrIoJEmSJEmSlIMsCkmSJEmSJOUgi0KSpk0QBAeDIHhV1DkkSZJyWRAEdwdB0BkEQUHUWSTNbRaFJEmSJClLBEGwHLgMyABvijaNpLkuGXUASdlt4hOq/wW8Y+Kh7wN/EobhcBAEtcDXgUuBNLATuCIMw3QQBH8C3ACUA0eAj4Rh+LPZzi9JkjTPvA94EPgV8H7gRoAgCJYC/5fxglEc+F4Yhn8w8dzvAh8FGoAW4LfDMNw++9ElzTaLQpJm2p8DFwNbGP/E6kfAXwD/DfgYcAiomzj2YiATBEEA/AFwQRiGRyY+8UrMcm5JkqT56H3A3zNeFHowCIKFwHHgx8BdwHuBMeB8gCAI3g78NfBm4BFgFTA666klRcKikKSZ9lvAH4ZheAwgCIJPAF9ivCg0CtQDjWEY7gXunThmDCgANgRB0BaG4cEogkuSJM0nQRBcCjQC3w/D8HgQBPuA9zA+c2gx8P+FYZiaOPy+ie8fBD4dhuHDE/f3zmZmSdGyp5CkmbYYaDrpftPEYwCfYfzC444gCPYHQfCnABMFoj9m/FOrY0EQ/EsQBIuRJEnSS3k/cEcYhscn7n934rGlQNNJBaGTLQX2zVI+SXOMRSFJM+0I459YnbBs4jHCMOwNw/BjYRiuZLwR4keDILhq4rnvhmF44tOuDON9iSRJknQKQRAUMd7D8YogCI4GQXAU+C/AucCzwLIgCE61UqSF8SVjknKQy8ckTbe8IAgKT7r/PeAvgiB4mPHizl8C3wYIguCNwC7GP53qZnx9e3qip9AS4H5gCBjEnkKSJEkv5c2MX0udA4yc9Pj3J55rBT4VBMFfTRy3LQzD+4GvAH8fBMF9wHYmegqFYXjyTG9JWcqZQpKm262MF3FOfBUy3rTwSWAH4xcbfzNx7Brgp0Af8ADw+TAMf854P6FPMd4U8SiwAPiz2RuCJEnSvPN+4GthGDaHYXj0xBfwWeDdwDXAaqCZ8Y0+3gkQhuGNwCcZX2rWC9wMVEeQX1IEYplMJuoMkiRJkiRJmmXOFJIkSZIkScpBFoUkSZIkSZJykEUhSZIkSZKkHGRRSJIkSZIkKQfNlS3pC4ALGN8mcSziLJIkafolgHrgYWA44iz6Na/BJEnKbi95DTZXikIXAPdGHUKSJM24y4D7og6h53gNJklSbjjlNdhcKQq1AnR29pNOZ6b95DU1pbS39037eecix5q9cmm8jjU7OdbsNNmxxuMxqqpKYOI9X3OG12DTxLFmJ8eanXJprJBb43Wsv+l012BzpSg0BpBOZ2bkguTEuXOFY81euTRex5qdHGt2muJYXaI0t3gNNo0ca3ZyrNkpl8YKuTVex/qiTnkNZqNpSZIkSZKkHGRRSJIkSZIkKQfNleVjkiRlhUwmw7Fjx2hrayedzv6VUseOxUmn0897LJnMp6qqjkTCywxJkjS3jI2l6OxsI5UaiTrKWXnhNVg8nqCoqJTS0gpisdikz+PVmiRJ06izs41kMk519UISieSU3pTno2QyTir16wuSTCZDf38PnZ1t1NbWR5hMkiTpN3V2tlFYWExJyaJ5fZ128jVYJpNhbCxFb28XnZ1tVFcvmPR5XD4mSdI0GhkZoqqqlmQyb15faJypWCxGSUn5vP/0TZIkZadUaoSSkvKsuk6LxWIkk3lUVtYwMjI0pZ+1KCRJ0rTKEIvl9ttrNl1kSZKk7JOt1yrj16BT230tt69aJUmSJEmScpRFIUmSstxXv/olRkdHp/xzu3Y9zSc+8RczkEiSJEln4g/+4Pe4//57p+18FoUkScpyX/vaP52yKJRKpV7y59at28Bf/dXfzFQsSZIkRczdxyRJymJ/93f/C4Drr/8AsVic+vp6KioqaW5uYmBggK9//bt84hN/QXNzE6OjIyxZspQ/+7O/pLy8nO3bH+Fzn/u/fPWr36K19Qgf/OB7edOb3sqDD97P0NAQf/qnf8m2bVsjHqEkSdL89PWvf4Wenm5uuOFjAHR3d/Ge91zHn//5J/jGN77KyMgwY2NjvO99H+BVr3rtjGSwKCRJ0gy6f0cr9z3ZOiPnvnRzPZec89Lbvn/sY3/CTTfdyBe+8M8UFxfzyU/+NXv27Oazn/0yRUVFAPzRH32cyspKAL785c/zne98g+uv/8PfOFd3dzebNm3mQx/6fe644yd88Yv/wD/909enfVySJEmzIerrtKuvfiMf+tD7+chH/ohkMsmdd97GJZdczqZNm/n8579CIpGgo6Od3/md93LhhS+jvLx82nNaFJIkKcdceeVVzxWEAG677cfcccdtpFKjDA4OsXTpslP+XFFRMZdcchkAGzeew2c/+39mJa8kSVI2WrRoEcuXr+LBB+/n0kuv4NZbf8wNN3yUrq5O/uf//O8cOtRMIpGkp6eb5uYmNm06Z9ozWBSSJGkGXXLO6T8lmm3Fxb8uCD3xxGPcfPO/8YUv/DNVVVXcccdt3HLLD0/5c/n5ec/djsfjjI29dE8iSZKkuWwuXKe9/vVv5Cc/+TH19Uvo7+/j3HPP44//+CNccsnl/O3ffoZYLMa73vVWRkaGZ+T1s74otLuli+372tm6qibqKJIkRaK4uIT+/j6Ki4t/47ne3l5KSkqpqKhgZGSE//iPWyJIKEm5ZyydJp3OkEzEicVis/ramUyG3oFRWtv7ae0Y4Gj7AKkMLKosZE1DJUsXlBKPz24mKVddccUr+cd//Hv+5V++zete90ZisRi9vb3U19cTi8V4+OEHOXy4ZcZeP+uLQg/vOsaDO4+y9Y8vjzqKJEmReNe7fosbbvgwBQWF1Nc//9Owiy9+OXfc8RPe/e63UlFRyZYt5/H00zsjSipJ2W9wOMVd2w9x+0Mt9A2OEo/FKMhPUJifoCAvQUF+gqKTbo8/nhx/vCBBUX6SooIkRQUJCvOTFBckKSxIjD+Wn3xeMSc1lqata5Cj7QO0dgzQ2t7P0fYBjnYM0D/069me+ck4JUV5dPaOz0QozE+wekkFaxoqWNNQyYrF5RTkJWb9z0rKBYWFhRNLx/6d739//MO566//A/7u7/4XX/3ql1m/fgOrVq2ZsdePZTKZGTv5FCwHDrS395FOT2+eWx9s4gd37+Nz/+VyigqyvgZGXV0ZbW29UceYFbk0Vsit8TrW7JQrYz16tImGhhWkUumoo8yKZDJ+yrEePdrEokWNz92Px2PU1JQCrAAOzla+bBEEQQ3wLWAVMALsAT4EVAFfAuqBFPAw8JEwDAcneerlzNA1GOTOv3twrNlqOsc6MJTiZ4+2cMfDLfQPpdi8qoY1DRUMj44xNDLG8MjE9+fdTzE0On57eGSMyfwrLchLUFiQIC8Rp7N3mLGT/m1XlOZTX11MfU0Ji2qKqa8uZlFNMdXlhSxcUM6uvW3sOdTFnkPd7DnUxeG2fjJAIh6jcVEZaxoqWNtQyeqGCsqK86flzyUKufR3GHJrvJMZ6wuvUear6boGy/oqSXVZAQAdvcMsyYGikCRJykoZ4NNhGN4NEATBZ4BPAf8D+GgYho8FQRAHvgd8fOJxSXPAwNAodz5yiDsfbmFgOMWW1bVcc8lyVtRPbRehdCbDyOgYg8NjDA6nGBxJMXTi9nCKwZExhiYeHxxOMZJKU1tRyKITRaDq4tN+SF5TUUhNxSIu3rgIgP6hUfYd7mZ3y3iR6GePjs9wAlhcW8LG5dVsXFFNsLSSgvyzm0mUyWRo6x5iV1MnYXMX1eUFXLBuAUsXlM768jopl2R9laS6vBCAzp4hltSWRJxGkiRp6sIw7ADuPumhB4HrwzA8yMSnfmEYpoMgeAhYP9v5pPmiu3+E0dExxjIZ0ukMY+nf/H7y7QXdwxQnY5SXTH1WTN/gKHc+3MJPH21hcHiM89bU8qZLVtC4qOyMssdjMQrzkxTmJ6ma+OB7ppUU5rF5VS2bV9UCMJoa4+DRXna3dLGruYu7Hz/MnY+0kEzEWNNQyaYV40WihgWlxCdRyOnsHWZXcyfPNHXyzMFO2nuGACgrzqN/MMV/PNDEoupiLli3gAvXL2BJXemMjlfKRdlfFDppppAkSdJ8NzEj6Hrglhc8XgR8APizKHJJc9mhtj6+//O9PLW/44x+vrw4jyV1pTTUldJQV8KSulKW1JaccnZM78AIdzzcws8ePcTQyBjbgjqueflyli08s2LQXJKXTLCmoZI1DZW84WUwMjrG7kNd7DzQwc4DHdx49z5uvHsf5SX5bFxexcYV1WxcXk1F6fjvZH2Do4QnikBNnbS2DwBQUphk3bIqrr5oGesbq6ivKaZ3cJTtYRsP7zrGjx84yL//8iBLaku4YN0CLli/gPoaP/CXpkPWF4UqywqIxaBjouosSdLMipHJ5EY/oRczR/oVZrN/BPqAz554IAiCJPAvwF1hGE55C7mJXgMzoq5u/v8iPFmOde7p7BniO7fv4s5fNVFUmMd7XruOusoiEokYiXiMRDxOPB577n4yHif+3HMxBoZSNB3tpfloDwdbe7jnySMMj4wBEIvBouoSGuvLaKwvp3FROfsOdfEf9x9geHSMSzYv5l2vDmic4jKxKJ3Jf9cliyt5xYXLAWjvHuTx3W08Frbx2O5jPLDzWQBWLC4nFotx4Eg3mcx4I+sNK2u4+mUr2LymlhWLK0i8YLezBcCqxhre/pp1dPYM8csnj3DvE0f40f0HuPm+A6xYXM6l5y7hsi1LqD+DFSHz5e/wdMml8Z5urMeOxUkkYlmxLDGZjD/vfiaTJpGIT+m/d9YXhZKJOFVlBXT0OFNIkjTz8vML6eg4TklJBYlEMisuOKYik8nQ399DMjl/G5DOZUEQ/G9gDXBNGIbpiccSwHeATuCGMzmvjabPnmOdW4ZHx7jjoWZu/VUzqVSaV25r4E2XrKC0KG9K5wkaq2moLuKSDQuA8b4+bV2DHDrWz+G2Pg619dHU2sOvdh4lk4EYcOGGhbzx5cufa10x1/+sTpiu/66bl1exeXkV733NGlqe7eOpA+3sPDA+Q+vaS1awfnkVK+rLSSZ+/ctsR3vfac97YVDHhUEdnb3DPLLrGA/tepZv/eQZvvWTZ2hcWEbjolJqK4qorSyktqKIuopCykvyT/k+PB/+Dk+nXBrvZMYajyfp7u6ipKR8Xl+nndxoOpPJMDaWore3k0Si4Hl/Bic1mj71eWY86RxQW1lER68zhSRJM6+qqg4Yoq3tWdLpsajjzLh4PE46/fyZUclk/sSfg6ZTEAR/C2wD3hCG4fDEY3Hg68AY8DthGDpNSzktncnwwFNH+eE9++nsHWbr2jrefuUqFlYXT8v547EYC6uKWVhVzLbg1/+fG02NceT4AMWFSeoqi6bltea7eGx8x7LGRWW84WXLp+28VWUFvPqCpbz6gqW0dw/x8K5jPL6njcf3HKdnYPR5x+Yl49RWjBeJaisKnysYrR9NU5LMjpkimrqqqjo6O9vo6+uKOspZeeE1WDyeoKiolNLSiimdJ2eKQvsPdUcdQ5KUA2KxGHV1C4jFcuOXglz69DFKQRBsZLxX0G7gl0EQABwAvgL8NvAU8OjE4/eHYfj7EUWVIvNMUyf/etcemp/tY/miMn7vmg0Ey6pm5bXzkokzbiCtM1dTUcjVFy3j6ouWAeMzxI53D3G8a3D8e/fE964h9h/ppn8o9dzPNi4q4/UXN7JtbR3xuMWhXJJIJKmtrY86xlmbrmuwnCkKPfLMs2QyGavBkiRp3gnDcCfjK1NOxYsb5bTW9n5u/Pk+Ht97nJryAn7vmg1cuGHhpHa/UnYpyEuwpLbkRXedHhhKcbx7kGM9w/zbXXv4ws1PsaCqiKsvWsYlmxaRl/zNxuFStsuJolBdZREjo2n6h1JTXkcsSZIkaW5JZzIcbO3lvh2t3PP4EfLz4lx3xUpeff5S8vP8xV6nVlyYZFlhGds2LWbrqhq2727jJ79q4pu3hfzo3gO86vwGXnFeA8WFOfFrsgTkSFGodmJdb0fPkEUhSZIkaR5KjaUJW7rYvnu8f0xn7zCJeIwrtizm2ktXUF5ig3tNXjwe4/x1C9gW1LGrqZNbf9XMv/1iP7c+2MSVW5bw6guWUllaEHVMacblVlGod5hlC13rK0mSJM0HwyNj7NjfzmN72nhibzsDwyny8+Kcs6KG866o5dzVtZQU+qGvzlwsFmP98mrWL6+m6WgvP/lVE7c91Mydj7Tw8k2LuPqiRha9SKPyTCbDaCrN0OgYwyPjX0OjYwyPjjGaSpNKpRlJjd8eTaUZHUv/+vZJX8vry7j83MXP25FNmi05URQ6sQNAZ487kEmSJElzWe/ACI/vPc5ju4+z82AHo6k0JYVJzltby9Y1dWxYUU2BS8Q0AxoXlfHhazfx1ssHuP2hFu7b0cq9T7SydmklsRgMThR+hkfHGJq4nc5MfdPHRDxGMhknLxEnHo9x345W7ny4hbe/YjXnram1D65mVU4UhSrLCknEY3T0DkcdRZIkScoZfYOjHOscZGgkxeDwGEMjKYZGTvo+8djgxGP9gymaj/WSyUBNeQFXnLuYrWvrWLO0gkTcWRSaHQuqinnvawPedOkKfvpICzsPdJCfl6CiJJ+CygQF+QkK8xIUFiQoyEtQmJ+c+D7+XH4yTn5egrxkfPwrEf/17WT8eX+XM5kMT+5r5/s/38tnf7iDtUsreecrV7OivjzCPwHlkpwoCiXiMSpL8+lwppAkSZI04waGUtz2UBN3PNzCyGj6lMck4jEK88d/kS4sSFKYn6C0OI83vGw529bWsWxhqTMmFKmKknyuu2IV112xasZeIxaLce7qWjatrOaeJ1q5+d79/I9vPMLFGxdy3eWrqKkonLHXliBHikIAVeWFdPQ4U0iSJEmaKaOpND/ffogfP9BE3+AoF65fwMUbFlFUkKBoovBTmD/+PS8Zt+gjTUjE47zivCVcvGEhtz44XlB9ZFcbr7lgKW94WSNFBTnzq7tm2aT+ZgVBcBAYmvgC+JMwDG9/wTHFwNeAbUAK+HgYhj+etqRnqbqsgAOtPVHHkCRJkrJOOp3hwaePctM9B2jvGWLj8iquu3IVyxe5BEaaiqKCJNddsYortyzhh/fs49YHm7j3ySNce+kKrtiy2GWUmnZTKTe+LQzDp17i+Y8DPWEYrg6CYA1wbxAEq8Mw7Du7iNOjpryQ7bvbSGcyxP1EQpIkSTprmUyGHfvb+cHd+znU1kfjwjL+0+vWsXFFddTRpHmtpqKQ371mI686fyn/etdevn3Hbn726CHe/orVrKwvZ2A4xcBQioGh0V/fHk7RPzTK4HO3U4yNpXn31etZWl0U9ZA0R03nHLR3Au8HCMNwTxAEjwCvA26cxtc4Y9XlhaTGMvQOjFJRkh91HEmSJGle23ekmx/8fB9hSxcLKov48LUbOX/dAj+AlabRivpy/uQ95/H4nuN8/+59/MMPnnzJ4xPxGCWFSYoK8ygpTNLTP8In/ukB3nXVGq7a1uCSTf2GqRSFvhMEQQy4D/ivYRh2veD5ZUDTSfebgaVTCVNTUzqVw6dkeUMlAJlEnLq6shl7nbkg28d3slwaK+TWeB1rdnKs2SmXxioJDh3r5Ss37eDR3W2UF+fxW69eyxVbFpNMuKxFmgmxWIzz1tZxzqoaHnrmWQaHxyguTFJckBz/Xpj33O38F/TqGhpJ8Y3bd/Pdn+6htX2Ad79qjf9W9TyTLQpdFoZhSxAEBcD/AT4L/PZ0h2lv7yOdzkz3aamrKyOZGT/vvqYOKguzt0lXXV0ZbW29UceYFbk0Vsit8TrW7ORYs9NkxxqPx2b0wx9JMyOTydDWPUTz0V6anu3l4NFenmnqJC8Z582XruA1Fy6lMD97r62luSSZiPPyTfVT+pnC/CR/9p8u5Es/eJyf/KqZox0DfOQtmygpzJuhlJpvJvV/8DAMWya+DwdB8HngllMc1gw0Am0T95cBP5+OkNOhqrwAwB3IJEmSpFNIpzMc7Rig+dnxAlDT0V6anu1jcDgFjC9LWVJbwpsuW8mVm+sptyWDNC8k4jHe/orV1NeU8I3bdvE333yUP3rbZhZVF0cdTXPAaYtCQRCUAMkwDLsnlo+9C3j8FIfeCHwIeGSi0fQFwLunM+zZKCvKIy8Zp6N36PQHS5IkSTmg5Vgf9zx+hKZne2k+1svIaBoYn5GwdEEpF21YSOPCUhoXlbGktpS8ZDynZkNK2eTSzfUsqCrisz/cwd984xE+8pZNbFhuU/hcN5mZQguBfwuCIAEkgKeBjwAEQfA48PowDI8AnwG+HgTBXmAM+L0wDOfMu0UsFqOqrMCZQpIkScp5wyNj/Oj+A9zxUAvJZIzGhWVcvnkxjYvKaFxYxqKaYvuOSFlo7dJK/tv7z+cffvAkf/+vT/Dbr1nLlectOaNzpTMZBodTFBckbWA9j522KBSG4X7gvBd5bstJt/uBt09ftOlXXVbgTCFJkiTltCf3tfPtO0KOdw9x+bn1vO3K1ZQW2V9EyhV1lUX81/du40u37OSbt4ccOd7PO69aTSJ++kJwe/cQOw92sPNAB880ddI3OEp+Mk5VeSE15QVUlxVSXV5AdXkhNeUTt8sKKchPzMLIdCZyqitcdXkhzzR1Rh1DkiRJmnVdfcN876d7eHjXMeprivmT95xHsKwq6liSIlBUkOSG6zbz/Z/v5Y6HWzjaMcCHr91E8Qs2ZRocTrGruZOnD3Sy82AHRzsGAKgozefcVTUsqSulu3+Y9p5hOnuGeOpAO919I7xw+6iSwiQ15YXU15awvrGKdY1VLKgsmqXR6qXkWFGogK6+YcbS6UlVQSVJkqT5Lp3J8IvHDvODX+xjNJXhLZet4OqLGslLej0s5bJ4PMa7rlrD4toSvnV7yCe/9Qh/eN1m+gdH2Xmgg50HO9h/pIexdIb8vDjB0iqu3LKYjSuqWVxb8qJLxlJjabp6h2nvGaKjd5iOniE6esbv72ru5FdPPwtAbUUh6xqrWD/xVVlaMJvD14TcKgqVFZLJQHffCNXlhVHHkSRJkmZUy7E+vnnbLvYd6WF9YxXve23AQnccknSSy89dzILKIj530w7+65cfBCAGNC4q4+qLlrFheTWrl1RMupCcTMSprSyi9hQzgTKZDK3tAzzT1Mmupk4e293GfU+2AlBfU/xcgShYVuWy1lmSW0Whk7altygkSZKkbDU8MsYt9x/g9odaKC5M8rtv3MDFGxfaDFbSKa1rrOK/vf987n2ylaULSlnfWEVZcf60v04sFmNxbQmLa0u4alsD6XSGlmN9PNPUydNNHdy/4yh3bT9MDFi2sIyVi8tZVFPM4poS6muKqSor8P9j0yy3ikJl44Wg8WbTFdGGkSRJkmbAyY2kL91czzteYSNpSae3oKqY665YNauvGY/Hxnc9nJiVlBpLc6C1h2cOdvJM0/hSs4Hh1HPHF+QnqK8upr6mhMW1xSyqHv9eV1nkjolnKLeKQifNFJIkSZKySTqdea5prI2kJc1HyUScNQ2VrGmo5E2XriCTydAzMErr8X5a2/s50j5Aa3s/u5o7eWDn0ed+LhGPsaCqiHPXLmDtknLWN1ZRkOeOZ5ORU0WhooIkBfkJOnrcll6SJEnZY2AoxZdu2cmO/e1ctbWBd7xytY2kJc17sViMipJ8KkryWdf4/CL34HCKox0DHDneT2v7AIfb+vjF9hZue2CMvGSc9Y1VbF5Vw+ZVNdRWuNPZi8mpolAsFqO6rICOXmcKSZIkKTsc6xzg//7gSZ7tGOS9rw14xXlLoo4kSTOuqCDJivpyVtSXP/dYZVUx928/xBP7jvPk3nae3NcOwJK6EjavquHcVbWsWlLubuQnyamiEEB1eaEzhSRJkpQVwuZOPnfTU2QyGT72znNZv7w66kiSFJm8ZIKNK6rZuKKad1+V4WjHAE/ua+eJvce546EWfvJgMyWFSc5ZOT6DaNPKmpzvuZZ7RaGyAlqO9UUdQ5IkSTor9zxxhG/dHlJXWcQfvW2zW81L0klisRj1NSXU15Tw2guXMTCUYufBDp7ce5wn97fz4NPPEovByvpyzllVwzkra2hcVEY8x3Y3y72iUHkhPf0jjKbSrrOWJEnSvDOWTvP9u/Zx5yMtbFxRzfXXbqS4MLc/6Zak0ykuTHLBugVcsG4B6UyGA6097NjXzo797fzo3gPcfO8Byovz2DQxi2jjimpKcuD/rblXFCob34Gss2+YBZU2m5IkSdL8MTCU4ou3PMVT+zt41bYG3nnVantjSNIUxWMxVi2uYNXiCt582Up6+kd46kA7O/Z38MTe4/zyqaPEYrBqScX4UrOVNSxdWJqVs4hyryhUXghAZ8+QRSFJkiTNGycaSh/rHOR9VwdcucWG0pI0HcpL8nn5pnpevqmedDrD/olZRE/ub+eme/Zz0z37KS/JZ92yStY3VrGusYoFlUXEzrJI1NEzxJ5D3ew91M26xkq2BQumaUSTl4NFofGZQh097kAmSZKk+WFXUyefu2kHAB995xbWv2BrZknS9IjHY6xeUsHqJRW85fKVdPeP8NT+dp460MGupk4eeuYYAFVlBaxbVjVRJKo87bb36UyG1uP97DnUze5DXexp6aZ9YhOsgrwEtZWFMz62U8m9olDZ+B90R687kEmSJGnu+8Xjh/n2HbtZUFXEDW/bzMIqG0pL0mypKMnnknPqueScejKZ8R3NdjV18kxzFzv2t/PAzqMA1KKPTNMAACAASURBVFYUsq6xivXLxmcSlRblcfBoD3sOdbOnpYu9h7vpH0oB4zOT1jZU8JoLlrJmaQVLF5RGthQ454pCBfkJSgqTzhSSJEnSnPerp5/lG7eFbFpRzYev3URxYc5dvkvSnHHyjmav2NpAOpPhSFs/zzR3squpk8d2t3Hfk60AJOIxxtIZABZVF7N1bR1rGipZu7SCumlYejZdcvJdpaqskI4eZwpJkiRp7jp8vJ+v/2QXqxsquOFtm0kmbCgtSXNJPBajYUEpDQtKefX5S0mnM7Qc6+OZpk56B0ZYtaSC1Q0VlBfnRx31ReVkUai6vICOXmcKSZIkaW4aHE7xuR/uoCA/wfXXbrIgJEnzQDweo3FRGY2LyqKOMmk5+e5SXe5MIUmSJM1NmUyGf771GY51DnL9tRupKiuIOpIkKUvlZFGopryA/qEUw6NjUUeRJEmSnuf2h1p4NGzjbVeuIljmLmOSpJmTk0Wh53Ygc7aQJEmS5pCwuZMf3L2PbUEdr71wadRxJElZLjeLQuXjU3DtKyRJkqS5orN3mC/8aCcLqor4wOvXz5mdaSRJ2Ssni0JV5RMzhbqdKSRJkqTopcbSfOFHTzE0kuL337KJooKc3A9GkjTLcrMoVOpMIUmSJM0dN/58H3sPdfOfX7eeJXWlUceRJOWInCwK5SXjlJfk21NIkiRJkXvomWe585EWXrWtgYs2LIw6jiQph+RkUQiguqzAmUKSJEmK1OHj/Xzt1l2sXlLBO165Ouo4kqQck7tFofJCZwpJkiQpMoPDKT5/0w4K8uJc/+ZNJBM5e2kuSYpIzr7znJgplMlkoo4iSZKkHJPJZPjarc/wbMcgH752E1VlBVFHkiTloNwtCpUXMjwyxuBwKuookiRJyjF3PNzCI2Eb1125knWNVVHHkSTlqBwuCk3sQNZjXyFJkiTNnrC5kxt/vo9ta+u4+sJlUceRJOWw3C0KlRUC0NFrXyFJkiTNjl1NnXzupqeoqyriA29YTywWizqSJCmHJaMOEBVnCkmSJGm2ZDIZfvroIf71Z3tZWF3EDW/bTFFBzl6KS5LmiJx9J6oozScWc6aQJEmSZtbI6BjfvD3kl08dZcvqWn73mg0WhCRJc0LOvhsl4nEqSwucKSRJkqQZ0949xGdv2kHT0V7efOkK3njJcuIuGZMkzRE5WxSC8SVkHT3OFJIkSdL0C5s7+fzNTzGaSvOH153DeWvqoo4kSdLz5HZRqKyQpmd7o44hSZKkLHJy/6AFVUX84XXnUF9TEnUsSZJ+Q24XhcoLeHzvcTKZjDs/SJIk6ay9sH/QB9+4geLCnL7kliTNYTn9DlVdVshoKk3v4CjlxflRx5EkSdI81tEzxD/+cLx/0LWXruAa+wdJkua4KRWFgiD4K+CvgXPCMHzqBc99HXgVcHzioRvDMPzkNGScMSe2pe/sGbYoJEmSpDO2Y99x/ufXH7Z/kCRpXpl0USgIgq3AxUDTSxz2qTAMP3vWqWZJdXkhMP6pTuOisojTSJIkaT6698kjfPO2kLpK+wdJkuaXSRWFgiAoAD4HvBu4eyYDzabqsvGZQh29bksvSZKkqevuG+Y7d+5m48oafs/+QZKkeSY+yeP+O/DtMAwPnua4jwZBsCMIgpuDIFh/dtFmXllJPol4zG3pJUmSdEb+44EmUqkMv/+2cy0ISZLmndO+cwVB8DLgfOBPT3PonwOtYRimgyB4H3BbEAQrwzAcm2yYmprSyR46ZXV1p14eVltZRP/I2Is+Px9l01hOJ5fGCrk1XseanRxrdsqlsUona+8e4u7HD3Pp5kUsriulra036kiSJE3JZD7OuAJYDxwIggCgAbg9CIL/HIbhHScOCsPw8Em3vxkEwf8/cexL9SB6nvb2PtLpzGQPn7S6urIXfZOuKMmnta0va97EX2qs2SaXxgq5NV7Hmp0ca3aa7Fjj8diMfvgjReGW+w8AcM3LV0ScRJKkM3PaolAYhp8CPnXifhAEB4E3nmL3sSUnCkNBELwWGAMOM8dVlxewp6U76hiSJEmaR452DHD/jqO8ctsSaioKo44jSdIZOauFz0EQPA68PgzDI8A3giBYCKSBHuBNYRimpiHjjKouK6Sr7xjpdIZ4PBZ1HEmSJM0DN9+7n2QyxhtetjzqKJIknbEpF4XCMFx+0u0tJ91+1TRlmlXV5QWMpTN0949QNbEbmSRJkvRiWo718dAzx3jDyxqpKMmPOo4kSWcs57dIqC4fn+7b0TtkUUiSJM1JQRDUAN8CVgEjwB7gQ2EYtgVBcDHwJaAIOAj8dhiGx6LKmgtuumc/RQVJrr5oWdRRJEk6K5Pdkj5rVU8Ugjp7hiNOIkmS9KIywKfDMAzCMDwH2Ad8KgiCOPBt4PfDMFwL3MNJvSA1/fYd7ubxvce5+qJllBTmRR1HkqSzYlFoYqZQe89QxEkkSZJOLQzDjjAM7z7poQeBRmAbMBSG4X0Tj38ReMcsx8spP7xnP2XFebz6/Iaoo0iSdNZyfvlYSWGS/Lw4Hc4UkiRJ88DE7KDrgVuAZUDTiefCMDweBEE8CILqMAw7JnvOmprS6Q86oa6ubMbOPdue2NPGM02dfPDaTSxdUvUbz2fTWE/HsWYnx5q9cmm8jnVqcr4oFIvFqC4rpKPXmUKSJGle+EegD/gs8JbpOGF7ex/pdGY6TvU8dXVltLX1Tvt5o5DJZPjaLU9RVVbABWtqfmNc2TTW03Gs2cmxZq9cGq9j/U3xeOwlP/zJ+eVjML4DmTOFJEnSXBcEwf8G1gDvDMMwDTQzvozsxPO1QHoqs4Q0OU/sa2ffkR7edMly8pKJqONIkjQtLAqBM4UkSdKcFwTB3zLeQ+jNYRie+DTrUaAoCIJLJ+5/GLgxinzZLJ3JcNM9+1lQWcQl59RHHUeSpGmT88vHYHymUE/fCKmxNMmEdTJJkjS3BEGwEfgzYDfwyyAIAA6EYfiWIAjeC3wpCIJCJrakjyxolnpk1zFajvXxu9ds8FpRkpRVLAoxvgNZBujqHaa2sijqOJIkSc8ThuFOIPYiz/0SOGd2E+WOsXSam+49wJK6Ei5avzDqOJIkTSs/6gCqywoA6Oi1r5AkSZJ+7ZdPHeXZjgHectlK4vFT1uUkSZq3LAoBVeWFAHT02FdIkiRJ40ZTaW657wAr6ss4b01t1HEkSZp2FoVwppAkSZJ+0z1PHKG9Z5i3Xr6KWMxZQpKk7GNRCCgqSFJUkHSmkCRJkgAYHhnj3395kGBpJRuWV0UdR5KkGWFRaEJ1eQEdPc4UkiRJEvxs+yF6+kd46xUrnSUkScpaFoUmVJcV0tHrTCFJkqRcNzCU4icPNrF5VQ1rGiqjjiNJ0oyxKDTBmUKSJEkC+OkjLfQPpXjLZSujjiJJ0oyyKDShuqyAvsFRRkbHoo4iSZKkiIym0ty1/RDnrqqhcVFZ1HEkSZpRFoUmVE9sS9/pDmSSJEk565HwGD0Do1x1fkPUUSRJmnEWhSY8ty29O5BJkiTlrLsePcTC6mI2LK+OOookSTPOotCEEzOFOpwpJEmSlJMOtPaw70gPV21dQtwdxyRJOcCi0IQqZwpJkiTltLsePURBfoJLzqmPOookSbPCotCE/LwEpUV5zhSSJEnKQT0DI/zqmWO8fNMiigqSUceRJGlWWBQ6idvSS5Ik5aZ7nzhCaizNVVttMC1Jyh0WhU5SXVZIR6/LxyRJknLJWDrNzx87zPrGKhbXlkQdR5KkWWNR6CTOFJIkSco9j+9pp6NnmFdtc5aQJCm3WBQ6SXV5IYPDKQaHU1FHkSRJ0iz52aMt1JQXcO7q2qijSJI0qywKnaT6xA5kNpuWJEnKCYfb+tjV3MUrtjYQj7sNvSQpt1gUOkl1eSEAnW5LL0mSlBPu2n6YvGScy89dHHUUSZJmnUWhk1SXj88UarcoJEmSlPUGhlL88qmjXLR+IaVFeVHHkSRp1lkUOkllaQExsNm0JElSDrh/RyvDo2NcZYNpSVKOsih0kmQiTkVpvtvSS5IkZbl0JsPPth9i9ZIKGheVRR1HkqRIWBR6gQVVxbQc64s6hiRJkmbQzgMdHOsc5JXblkQdRZKkyFgUeoFzV9fQ/Gwfx7sHo44iSZKkGfKzRw9RUZLP+cGCqKNIkhQZi0IvsHVtHQDbdx+POIkkSZJmwrHOAXbsa+eKLYtJJrwcliTlLt8FX2BhVTENdSVsD49FHUWSJEkz4K7th4nHY1yxxaVjkqTcZlHoFLaurWPPoW66+0eijiJJkqRpNDwyxn1PtrItqKOqrCDqOJIkRcqi0ClsXVtHBnh8T1vUUSRJkjSNHnj6KAPDKbehlyQJi0KntHRBKXWVhTy626KQJElStshkMtz16CGWLSxl9ZKKqONIkhQ5i0KnEIvF2Lq2jmcOdjIwlIo6jiRJkqbB7pYuDrX1c9XWBmKxWNRxJEmK3JSKQkEQ/FUQBJkgCDad4rniIAj+NQiCvUEQ7AqC4I3TF3P2bVu7gLF0hif3uQuZJElSNvjZo4coKUxy0YaFUUeRJGlOmHRRKAiCrcDFQNOLHPJxoCcMw9XANcBXgiAoPfuI0Vi5pJyKkny2u4RMkiRp3uvoGWL77uNcfu5i8vMSUceRJGlOmFRRKAiCAuBzwPUvcdg7gS8BhGG4B3gEeN3ZBoxKPBbjvLV1PLm/nZHRsajjSJIk6Szc/fhhMmR4xXluQy9J0gnJSR7334Fvh2F4MAiCFztmGc+fRdQMLJ1KmJqamZtYVFdXNuWfeeUFy7j7scO0dAxy8ab6GUg1M85krPNVLo0Vcmu8jjU7OdbslEtj1fw0mkrzi8ePsGV1LbWVRVHHkSRpzjhtUSgIgpcB5wN/OtNh2tv7SKcz037euroy2tp6p/xziyoKKC5IcvfDzaxaOD9Wwp3pWOejXBor5NZ4HWt2cqzZabJjjcdjM/rhj/RStu9uo3dglFe6Db0kSc8zmeVjVwDrgQNBEBwEGoDbgyB4zQuOawYaT7q/DGiZhoyRSSbinLu6lsf3Hic1lo46jiRJks7AUwfaKS3KY31jVdRRJEmaU05bFArD8FNhGC4Ow3B5GIbLgUPAa8MwvOMFh94IfAggCII1wAXAbdOcd9ZtC+roH0oRtnRFHUWSJElnIGzuIlhaSdxt6CVJep4pbUn/QkEQPB4EweKJu58BKoMg2Av8GPi9MAzn/dz5jSuqyc+LuwuZJEnSPHS8e5Dj3UOsXVYZdRRJkuacyTaafs7EbKETt7ecdLsfePv0xJo7CvISnLOihu272/itV6/1EyZJkqR5JGwen+29bplLxyRJeqGzmimUK7YGdXT3jbD/SE/UUSRJkjQFYXMXJYVJltSVRB1FkqQ5x6LQJJy7qoZEPOYSMkmSpHkmbOlkrf2EJEk6JYtCk1BcOL5bxfawjUwmE3UcSZIkTUJ79xBtXUMuHZMk6UVYFJqkrUEdx7oGOdzWH3UUSZIkTULY0glAYJNpSZJOyaLQJJ23po4Y8KhLyCRJkuaFE/2EGhaURh1FkqQ5yaLQJFWU5LO6oYJHQ4tCkiRJ80HY3GU/IUmSXoJFoSnYtraOQ219HOsciDqKJEmSXkJHzxDHugYJ7CckSdKLsig0BVvX1gGwfffxiJNIkiTppYTNXQCss5+QJEkvyqLQFNRWFrFsYSmP7j4WdRRJkiS9hLClk+KCJA119hOSJOnFWBSaom1r69h3uIeuvuGoo0iSJOlF7DrRTyhuPyFJkl6MRaEpOrGE7DF3IZMkSZqTOnuHOdY56NIxSZJOw6LQFC2uLWFhdbFb00uSJM1RYXMngE2mJUk6DYtCUxSLxdi2to6wuYu+wdGo40iSJOkFdjV3UVSQZOkC+wlJkvRSLAqdga1r6xhLZ3hir7uQSZIkzTVhcyeB/YQkSToti0JnYHl9GVVlBWx3CZkkSdKc0tk7zLOdg6xdaj8hSZJOx6LQGYjHYmxdW8dTBzoYHhmLOo4kSZImhC3j/YTWNVoUkiTpdCwKnaGta+sYTaXZsb896iiSJEmaEDZ3UVSQYNmCsqijSJI051kUOkNrl1ZQWpTH9j0uIZMkSZordjV3sabBfkKSJE2GRaEzlIjH2bKmlif2Hic1lo46jiRJUs7r6hvm2Y4B1rkVvSRJk2JR6CxsXVvH4PAYzzR1Rh1FkiQp54XNXQAEy+wnJEnSZFgUOgsbl1dRVJDkF48fiTqKJElSzgubOynMT7BsYWnUUSRJmhcsCp2FvGSC116wlO272zjQ2hN1HEmSpJwWtnSxdmklibiXuJIkTYbvmGfp1RcspbQojx/esz/qKJIkSTmru2+Y1vYBl45JkjQFyagDzHdFBUne8LJG/vWuvexq6mRdo40NJUnS9AuC4H8D1wHLgXPCMHxq4vE3Av8DiE18fSIMwx9GlTMqYct4PyGbTEuSNHnOFJoGrzhvCVVlBfzwnv1kMpmo40iSpOx0M3A50HTigSAIYsC3gPeGYbgFeC/wjSAIcu4aL2zusp+QJElTlHMXDDMhPy/BNZcsZ+/hbp7c1x51HEmSlIXCMLwvDMOWUzyVBiomblcCrWEYpmcv2dywq7mTNQ32E5IkaSp815wml55Tz4LKIn54z37SzhaSJEmzIAzDDPAO4EdBEDQxPpvofdGmmn3d/SO0tg+wzn5CkiRNiT2FpkkyEefNl63gy//+NI/sOsaF6xdGHUmSJGW5IAiSwJ8B14ZheH8QBJcA3w+CYEMYhn2TPU9NzcwtuaqrK5uxc5+w6/BhAC7avHhWXu/FRPnas82xZifHmr1yabyOdWosCk2jCzcs5NYHm7jpnv1sC+qcvixJkmbaFmBxGIb3A0wUhvqB9cDDkz1Je3sf6fT0z3Suqyujra132s/7Qg/vbKUgP0F5QWJWXu9UZmusc4FjzU6ONXvl0ngd62+Kx2Mv+eGPVYtpFI/FeMvlK3m2c5D7dxyNOo4kScp+h4CGIAgCgCAI1gMLgX2RppplYXMXaxoqSCa8tJUkaSp855xmW1bXsnJxObfcf4DR1FjUcSRJUpYIguAfgiA4BDQAPw2CYGcYhkeB64EfBEHwBPAvwAfCMOyIMuts6ukf4cjxfoKl9hOSJGmqXD42zWKxGNddvpLP/Mvj3P3YEV59wdKoI0mSpCwQhuENwA2nePw7wHdmP9HcsLulC4B1y6oiTiJJ0vzjTKEZsH55Nesbq/jxAwcZGklFHUeSJClr7WrupCAvQeOi3GksKknSdLEoNEPeesVKegdGufORQ1FHkSRJylphcxer7SckSdIZ8d1zhqxaXMF5a2q57VfN9A2ORh1HkiQp6/QMjHD4eD/rltlPSJKkM2FRaAa95bKVDA2nuO1XzVFHkSRJyjq7m8f7CQX2E5Ik6YxYFJpBDQtKuWjjQn76SAvdfcNRx5EkScoqYXMX+XlxlttPSJKkM2JRaIZde+kKxtIZfvzLpqijSJIkZZVdLZ2sWWI/IUmSztSktqQPguBmYAWQBvqAPwzD8PEXHPPXwEeAIxMP3R+G4e9PX9T5aWFVMZdtrufuxw/z2guXUltZFHUkSZKkea93YITDbf1ctH5h1FEkSZq3JlUUAt4fhmE3QBAE1wL/DGw9xXHfDMPw49MVLltcc8kK7ttxlB/df4DfecOGqONIkiTNe7tbxvsJrbOfkCRJZ2xSc21PFIQmVDA+Y0iTVFVWwFXblvDLp45y5Hh/1HEkSZLmvV3NXeQn4yyvt5+QJElnatILsIMg+EoQBM3AJ4H3v8hh7wqC4MkgCO4IguBl05IwS7z+4kby8xLcfO/+qKNIkiTNe2FzF6sb7CckSdLZmOzyMcIw/CBAEATvBT4DvP4Fh3wR+GQYhqNBELwa+FEQBOvDMGyf7GvU1JRO9tApq6uL9lOkOuCtV67me3eEtA+Msq6xeuZeK+KxzqZcGivk1ngda3ZyrNkpl8aquaFvcJRDbX28Zf3KqKNIkjSvTboodEIYht8KguDLQRDUnFzwCcPw6Em37wyCoAXYBPxisudub+8jnc5MNdJp1dWV0dbWO+3nnapLNy7k9gcP8plvPsJf/ecLKCqY8h//ac2Vsc6GXBor5NZ4HWt2cqzZabJjjcdjM/rhj3LL/iM9AKxZUhFxEkmS5rfTzrcNgqA0CIKlJ92/BuiY+Dr5uCUn3d4CLAfCaUuaBYoKknz4TZs43j3EN27bRSYz/QUwSZKkbNfaPt6jcUldScRJJEma3yYzVaUEuDEIghJgjPFi0DVhGGaCILgV+MswDB8B/jYIgm0Tx4wA7z159pDGrW6o4C2Xr+DffrGfDcurufzcxVFHkiRJmleOHO+ntCiPsuL8qKNIkjSvnbYoFIbhs8DFL/Lc60+6/WLNp/UCr7u4kV1NnXznzt2sXFxOQ53T6SVJkiartX2AxTXFUceQJGnec7uGCMRjMT54zUaKCpJ88Uc7GR4dizqSJEnSvJDJZGht72dxrUvHJEk6WxaFIlJRks/vXrOB1uP9fPfO3VHHkSRJmhd6BkbpH0pRX2NRSJKks2VRKEIbl1fz+pc1cu+TrTz4tO2XJEmSTqf1+HiT6fpal49JknS2LApF7M2XrWB1QwXfuC3k2c6BqONIkiTNaSd2HlvsTCFJks6aRaGIJeJxPnTNRpLxGF+8eSejqXTUkSRJkuasI+0DFOQnqCoriDqKJEnznkWhOaCmopAPvGE9Tc/2cuPde6OOI0mSNGcdOd5PfXUxsVgs6iiSJM17FoXmiPPW1PGq8xv46SOHeGxPW9RxJEmS5qTW9n6bTEuSNE0sCs0hb79yNY0Ly/jn/3iG9u6hqONIkiTNKQNDKbr6Rlhsk2lJkqaFRaE5JC8Z58Nv3shYOsOX/n0nY2n7C0mSJJ3Q2mGTaUmSppNFoTlmYVUx77s6YO+hbm6+90DUcSRJkuaM1uPjO7XW11oUkiRpOlgUmoMu3rCIyzbXc+sDTew82BF1HEmSpDmhtb2fZCJGXWVh1FEkScoKFoXmqPe8ei31tSX8078/zfGuwajjSJIkRa61fYCFVcUk4l7CSpI0HXxHnaMK8hJcf+1GUqk0n/7eYxzvtjAkSZJy25Hj/dTX2GRakqTpYlFoDltSV8rH372FgaEUn/7uY+5IJkmSctZoaoy27kEW209IkqRpY1Fojlu+qJyPvWsL/UMpPv297XT0WBiSJEm552jHIJkM1LvzmCRJ08ai0Dywor6cj71zC32Do3z6u49ZGJIkSTmntX18O3qXj0mSNH0sCs0TKxeX89F3bqF3cIRPf/cxOnuHo44kSZI0a44c7ycGLKq2KCRJ0nSxKDSPrFpcwUffsYWegRE+/d3tFoYkSVLOaG0foLaykPy8RNRRJEnKGhaF5plVSyr46Du30NU/wqe/54whSZKUG1rb++0nJEnSNLMoNA+tXlLBR99xLl19w3zm/7V339Fx3ved798z6L0DBFFIEOXH3ilSvdiSJdlykVscx3Y2ycZxNvEmOdlzNze+Sda78Tq2N3vj1LtxEjuK4yIX2Y6LFEmkREokxU6RFB8S7AUk0UiCDSzA/QOQTMuUBIoAZjDzfp2DI+DBg+H3pwcP5jef+ZWvbeLkGYMhSZKUuq4MDHCs5xyTDYUkSRpVhkITVGt9Kb/7/nn09g0FQ6cMhiRJUorqOnmBy1cGqa10PSFJkkaTodAE1tZQyu9+YB49p/v53Nc2cersxUSXJEmSNOqODu885kghSZJGl6HQBNfWUMrvvH8u3acv8PmvbaK3z+3qJUlSaunoPgfgmkKSJI0yQ6EUEBrL+N33z6Pr1Hn+8G+f48TJ84kuSZIkadR0dJ2lpDCb/NzMRJciSVJKMRRKES8HQ72n+/nvX17H9n09iS5JkiRpVBztdpFpSZLGgqFQCgmNZfz579xJaVEOf/7Nzfxk7UEGBwcTXZYkSdKbNjg4OLwdvYtMS5I02gyFUkxtZQF/+JFFLGyr4pvL2/n7H+yg/9KVRJclSZL0pvT29XPh4hXXE5IkaQwYCqWg3OxMfvPds3n4jmms3XGc//kvG+g65TpDkiRp4nl5kenJlYZCkiSNNkOhFBWLxXjHLVP55Pvm0nnyPJ/+8np2HuhNdFmSJEnX5afb0Tt9TJKk0WYolOLmtVTyqY8upig/iy98fTNPbTjsOkOSJGnC6Og+R35OJsUF2YkuRZKklGMolAZqKwr41EcXM7e5gq/++y7+6Uc7uXTZdYYkSVLy6+g6S21lPrFYLNGlSJKUcgyF0kReTia/9d45vPPWqax6sYPPfnUTvX39iS5LkiTpdQ3tPOZ6QpIkjQVDoTQSj8V49+3T+K2H53C0+yz/7cvr2HXoZKLLkiRJuqYz5y9x+twlJhsKSZI0JgyF0tDCtio+9ZFF5GZn8Gf/upHvPLuHy1cGEl2WJEnSzzjaNbTIdK2LTEuSNCYMhdJUXVUhf/SxJdw6u5Z/e/4A/+Mr6zl84kyiy5IkSXpFx8s7j7kdvSRJY8JQKI3l52byK2+fwW+/dw4nz/Tz6a+s40drDjAw4O5kkiQp8Tq6z5GdGaeiJDfRpUiSlJIyE12AEm9BaxXNdSU88njEt1bsYXN7F7/69hnUlDlUW5IkJc7R7rNMKs8n7s5jkiSNCUcKCYDi/Gx+892z+Y8PzeRo51n++B9fYPnGwwwOOmpIkiQlRkfXOWqdOiZJ0pgxFNIrYrEYN8+axKd/9SZa60t55Ild/Pk3t9Bz+kKiS5MkSWmm/+IVuk9fcJFpSZLG0Iimj4UQHgOagAHgDPDbURRtftU5GcAXgfuBQeCzURR9aXTL1XgoL87l9z4wjxWbjvCN5e380T+8wIfva2PZzBpiDt+WJEnj4FjPOQC3o5ckaQyNdKTQx6IomhdF0QLgC8A/XuOcDwMtQCtwM/AnIYSpo1Klxl0sFuPuhfX8t1+5icmVBfz9D3bwN49t4/S5i4kuTZIkUTmczwAAIABJREFUpYFXtqN3+pgkSWNmRKFQFEWnrvqyhKERQ6/2QeDvoygaiKKoE3gMeP+Nl6hEqinL579+eCHvu6uZLe1d/OH/WcOzW44y4FpDkiRpDB3tPks8FqOmLC/RpUiSlLJGvPtYCOFLwH1AjKEpYq/WCBy46uuDQMP1FFNRUXg9p1+XqqqiMXvsZDMWbf3YQ7O5a0kjf/vtrXz5xztZ+9IJfvN985haWzzq/9b1SKfrCunVXtuammxrakqntmr8dHSfo7osj8wMl8CUJGmsjDgUiqLo1wBCCB8BPg88ONrFdHefYWBg9EegVFUV0dnZN+qPm4zGsq35GTF+7/1zee7FY3xzeTv/+X+t4L6bGnjnrVPJzR7xr9KoSafrCunVXtuammxrahppW+Px2Ji++aPU09F91kWmJUkaY9f91ksURY8Ad4cQKl71rYPAlKu+bgQO3UBtSkKxWIzb5tbymV9fxm1zJ/GTtQf51JfWsmlXZ6JLkyRJKeLylQFO9J5nsusJSZI0pt4wFAohFIYQGq76+iGgZ/jjao8C/zGEEA8hVAHvBr41msUqeRTmZfHLD8zgD35pIfk5mfzld17ki9/aStfJ84kuTZIkTXAnes9zZWDQkUKSJI2xkYwUKgAeDSG8GELYDPwu8FAURYMhhB+FEBYPn/cIsBfYDawBPh1F0b4xqVpJo7W+lD/65SV84O4WXjrQy6e+tJYfrTnA5SvXWotckiTpjXV0D+885nb0kiSNqTdcCCaKouPAstf43oNXfX4F+MTolaaJIjMjzv1LG7lpRjX/+uRuvrViD89vO8ZH7msjNJYlujxJkjTBvLIdvSOFJEkaU+O/OrBSVnlxLr/18Bw2t3fx1Sd28Wf/uombZlTz8J3NVJe6nawkSTcihPAF4L3AVGBOFEXbho/nAv8beCtwAVgdRdGvJ6rO0dDRfY6K4pyEbGQhSVI68ZlWo25+SyUzppTxw9UHeOKFg2yIOrlnYT3vuGUKRfnZiS5PkqSJ6jHgL4CVrzr+OYbCoLbh6f01417ZKDvafdapY5IkjQNDIY2JnKwMHr5jGncvqON7q/by5IZDrHrxKA8um8JbFzeQk5WR6BIlSZpQoihaBRBCeOVYCKEQ+ChQH0XR4PB5xxNS4CgZGBzkWPc5QoNT0CVJGmuGQhpTZUU5/PIDM7h3SSPfXrGHbz+zl6c3HuHdtzVx65xa4vFYokuUJGkiawa6gT8OIdwNnAE+9XKANBH1nLrAxcsD1Fa6npAkSWPNUEjjoq6ygE++by7RwV6+uXwP//TjnTyx/hDvu7OZuc0VxGKGQ5IkvQkZwDRgUxRF/yWEsBT4QQihJYqi0yN9kIqKwjErsKqq6LrOP9B1DoCZzVXX/bOJNtHqvRG2NTXZ1tSVTu21rdfHUEjjKjSW8amPLmJ91Mm3n9nDX3xrK9MbS3n/3S001RYnujxJkiaag8Bl4GsAURStDSF0AW3A+pE+SHf3GQYGBke9uKqqIjo7+67rZ17a0wVAXgbX/bOJ9GbaOlHZ1tRkW1NXOrXXtv68eDz2um/+xEezKGkkYrEYS6ZX8z9+bSkfvreNI11n+e9fWc/ffW8bx3vOJbo8SZImjCiKuoDlwL0AIYQ2oBpoT2RdN6Kj+yxF+VluTiFJ0jhwpJASJjMjzlsW1XPL7En8eO1Bnlh3kPU7O7llziTeectUKt3GXpKkV4QQvgg8DEwCngwhdEdRNAv4DeAfQwj/C7gEfCSKopMJLPWGdHSfc+cxSZLGiaGQEi4vJ5OH75jGWxbW8cM1B1ix6Sirtx3jjnmTecctUykrykl0iZIkJVwURZ8EPnmN43uBu8a9oDEwODhIR/dZlkyvTnQpkiSlBUMhJY2Swhx+8a1t3H9TI/+2+gDPbjnKyq0d3L2gjgdvnkJJgcPIJUlKZafPXeLshcuOFJIkaZwYCinplBfn8tG3BR5Y2sgPntvPUxsO88yWI7xlUT0PLJ1CYV5WokuUJEljoKPrLIDb0UuSNE4MhZS0qkrz+JW3z+DBm6fw/VX7+MmagyzfeIT7ljRw35LGRJcnSZJGWUf3UCg02ZFCkiSNC0MhJb1J5fn8+jtn8fabp/C9Vfv4/vDooYfvbmVpqCI/119jSZJSwdGuc+RkZ7ieoCRJ48RX05ow6qoK+c33zOHAsT6+t2ofj/z4JR59ahd3Lajj3sUNdiAlSZrgjnafZXJFPrFYLNGlSJKUFgyFNOFMmVTEJ983l9P9V/jXn7zE4y8c5N/XHeLm2ZN4YGmji1NKkjRBdXSfZebU8kSXIUlS2jAU0oTVXF/Kb7xrNu+98zyPv3CQVVs7WLW1gwWtlTywbAotdSWJLlGSJI3QuQuXOXnmIrUVLjItSdJ4MRTShFdVmscv3Rd4521NPL3hME9tOMym3V201pfwwLIpzG2uIO4wdEmSklpHj4tMS5I03gyFlDKK87N59+3TeGDpFJ7depQnXjjIF7+1lbrKAu5f2sjSmTVkZsQTXaYkSbqGjq5zANRWGgpJkjReDIWUcnKyM7h3cQN3L6hj/c4T/GjNQf7hhy/xnWf3cu/iBu6cP5m8HH/1JUlKJh3dZ8nMiFFVmpvoUiRJShu+MlbKysyIs2zWJJbOrGHbvh5+svYg31zezg+e389dCybz1kXuWCZJUrI42nWWmrJ8MuKO6pUkabwYCinlxWIx5kyrYM60CvZ1nOYnaw/yk7UHeeKFQ9w8axJvW9pInUPVJUlKqI7uczROKkp0GZIkpRVDIaWVptpiPvHu2Zw4eZ4nXt6x7MUO5jVXcP/SRtoaSom5KLUkSePq0uUrdJ46z7JZNYkuRZKktGIopLRUPbxj2btua2L5xiM8ueEwf/avm2iqLeaBpY0sbKsiHjcckiRpPPT09TM4OLSjqCRJGj+GQkprRfnZvPO2Jt62tJHnX+zgJy8c5G8e20Z1WR73Lm7gltmTXJRakqQx1nu6H8C1/iRJGme+2pWAnKwM7l5Yz53z69i4q5Mfrz3IV/99F99+Zg+3zq7l7oV1THbdIUmSxkRvn6GQJEmJYCgkXSUej7F4ejWLQhV7O07z9IYjPLPlCE9tPMyMKWXcs7Ce+a0V7owiSdIo6um7ABgKSZI03gyFpGuIxWI0Ty6heXIJH7ynhZVbj7J80xH++rsvUl6cw13z67hj3mSKC7ITXaokSRNeb18/+TmZ5GbbNZUkaTz5zCu9geKCbN5+81TuX9rIlvZunt54mO88u5fvP7ePJdOruWdhPdMmF7trmSRJb1JvXz9lxY4SkiRpvBkKSSOUEY+zsK2KhW1VdHSf5emNR3juxQ5Wbz/OlJoi7llYx9KZNWRnZSS6VEmSJpSevn6njkmSlACGQtKbUFtRwIfvbePhO6axZvsxnt54hH/68U6+ubyd2+bWcveCOqrL8hNdpiRJE0JvXz9TagoTXYYkSWnHUEi6AXk5mdy9sJ67FtSx69BJntp4hCfXH+bxFw4xe1o59yysZ+60CuJxp5ZJknQtl68McPrsRcqKchNdiiRJacdQSBoFsViM0FhGaCyjt6+fZ7ccZcXmI3zxW1upLMnlrgV13D63lqJ8F6aWJOlqJ92OXpKkhDEUkkZZWVEO77qtibffPIVNu7tYvvEw31qxh8dW7uOmGdXcvbCOabUuTC1JEgytJwRQbigkSdK4MxSSxkhmRpwl06tZMr2aI51neHrTEZ7fdozntx1jyqQi7pw/maUzasjL8TaUJKWvXkcKSZKUML4alcZBXVUhH7kv8L47m1m9/RjLNx7hn38S8fWndrMkVHP7vMm01pc4ekiSlHZ+Ggq5ppAkSePNUEgaR3k5mdyzsJ67F9Sxt+M0K7d0sPal4zy37Rg15fncPreWW2dPoqTQd0slSemhp+8COdkZ5OVkJLoUSZLSjqGQlACxWIzmySU0Ty7hQ29pZd3OE6zcepRvrdjDd57Zy9zmCm6fW8uc5goyM+KJLleSpDHT29dPeVGOo2UlSUoAQyEpwXKyM7htbi23za2lo/ssq7Z28Ny2Y2xu76KkIJtbZk/i9nmTqaoqSnSpkiSNut6+ftcTkiQpQd4wFAohVACPAM3ARWA38PEoijpfdd6XgbcCXcOHHo2i6E9HtVopxdVWFPD+u1t4zx3TeHFPNyu3dvD4C4f48dqDtDWWsrC1iptmVFPq9DJJUoro7etn5tSyRJchSVJaGslIoUHgc1EUrQAIIXwe+Czwq9c497NRFP3V6JUnpafMjDgL2qpY0FbFyTP9rN5+jA27uvj6U7v5xlO7mT6ljKUza1gUqijIzUp0uZIkvSlXBgY4eabfRaYlSUqQNwyFoijqAVZcdWgN8ImxKkjSzyotzOGBpVP46Dtms3XnMdbuOM6aHcf58o938sjjEXObK1g6s4Z5LZXkZLlIpyRp4jh15iKDg1Du9DFJkhLiutYUCiHEGQqEvv8ap/xeCOHjwB7gD6IoeukG65N0ldqKAt59+zTedVsT+4/1sXbHcV546TibdneRk5XBgrZKls6oYVZTuQtUS5KS3k+3ozcUkiQpEa53oem/BM4A15oi9odARxRFAyGEjwI/CSFMi6LoykgfvKKi8DrLGbl0WqTXtqauq9tbXV3MTXPruDIwyPa9XTy76QjPbTnKmu3HKS7I5t6bGrn/5qlMqihIYMVvXjpdW9uammyr9MYMhSRJSqwRh0IhhC8ArcBDURQNvPr7URQduerzfw4h/G+gHjgw0n+ju/sMAwODIz19xKqqiujs7Bv1x01GtjV1vV57a0ty+eBdzbz39ia27e1h1YsdfHfFHr6zvJ05zRXcs7CO2U0VxOMTY7vfdLq2tjU12dafF4/HxvTNH01MPcOhUHmxawpJkpQIIwqFQgifARYBb4+iqP81zql7ORgKIbwNuAIcuda5ksZGZkac+a2VzG+tpOf0BZ7dcpRnNh/l/310K5Uludy9oI7b5tZSlJ+d6FIlSaK37wJZmXEKcq938LokSRoNI9mSfhbwB8Au4PkQAsC+KIreE0LYDDwYRdFR4CshhBpgADgNvDOKostjV7qk11NenMu7b5/GO26ZyqbdXSzfeJhHV+zhuyv3smR6DfcsrGPa5GJisYkxekiSlHp6+/opK8rxuUiSpAQZye5j24FrPlNHUTT/qs/fOop1SRolmRlxlkyvZsn0ao50nWXFxiM8t62D1duP0VhdyN0L61g2cxI52e5cJkkaXz19/e48JklSAjlWV0ojdZUFfPi+Nt571zTWbD/O0xuP8JWfRHz96XYWtVVx86xJzJhSNmHWHpIkTWy9p/tpayhJdBmSJKUtQyEpDeVmZ3LXgjrunD+Z9iOnWLW1g/VRJ89vO0ZJQTZLZ9awbFYNU2qKHNIvSRoTA4ODnDzTT1mRi0xLkpQohkJSGovFYrTWl9JaX8ov3dfGlvZu1uw4ztMbD/PEukPUVuSzbGYNS2dNoro0L9HlSpJSSN/Zi1wZGHQ7ekmSEshQSBIAWZkZLJ5ezeLp1Zy9cIn1O0+wevtxvrtyH99duY+WuhKWzaphyfRqdy+TJN2wV7ajNxSSJClhDIUk/ZyC3CzunF/HnfPr6D51gTU7jrFm+3H+5YldfO3J3cxqKmfJ9GoWtFaSn5uV6HIlSRNQ73AoVFZsKCRJUqIYCkl6XRUlubz95qk8uGwKh06cYc2O46x76Thb93STmRFjdlMFS6ZXM7+1krwc/6RIkkbmlVDINYUkSUoYX8FJGpFYLEZjTRGNNUW8/65m9nacZt1LJ1gfnWBze9dPA6IZ1cxvMSCSJL2+nr4LZMRjFOU74lSSpETxVZuk6xaLxWieXELz5BI+cE8Le4++OiCKM2daOUtmVDOv2YBIkvTzevv6KSvKIe4ul5IkJYyv1CTdkHgsRktdCS11JXzwLS3sOXKKdS+dYF10gk27u8jKjDNrajnzWyuZ21xBaaFrR0iSoPd0vzuPSZKUYIZCkkZN/Kot7n/hra20Hx4KiDa3d7K5vQuAptoi5rVUMr+lkobqQmK+QyxJaam3r5+ptUWJLkOSpLRmKCRpTMRjMdoaSmlrKOUX723lcOdZNrd3saW9i++t3MdjK/dRXpzzSkA0vbGUrMyMRJctSRoHg4OD9PT1s7CtKtGlSJKU1gyFJI25WCxGQ3UhDdWFPHTLVE6dvcjW9i42t3fx3IsdLN94hJysDGY1lTOvpYL7b52W6JIlSWPozPlLXL4y4PQxSZISzFBI0rgrKcjm9nmTuX3eZC5dvsJLB3rZ3N7NlvYuNu7q5GtP7mbZrEncs6CO+urCRJcrSRplP92O3lBIkqREMhSSlFBZmRnMba5kbnMlg/e1sbfjNGteOsGzm46wYtMRWutLuHthHYtDNZkZ8USXK0kaBT0vh0LFhkKSJCWSoZCkpPHyVvfL5tXzrlumsmprBys2H+H/fH8HX8/fze3zJnPX/DoqSnITXaok6Qa8PFKovMi/55IkJZKhkKSkVJiXxf1LG7nvpgZ27O9h+cYj/GjNAX605gDzmiu5Z2EdM5vKibt7mSRNOL19F4jHYpQUZCe6FEmS0pqhkKSkFo/FmN1UweymCrpPXeCZLUd4dvNRNrd3UV2ax10L6rh5Vg0lhU5BkKSJovd0PyWF2cTjBvuSJCWSoZCkCaOiJJeH72jmoVua2LDrBMs3HuGby9t5dEU7M6eUsWzWJBa2VZGX4582SUpmPX39lLvItCRJCecrJ0kTTlZmnGUzJ7Fs5iQ6us+yevtx1mw/xj/88CUeeTxifmsly2ZOYva0chenlqQk1NvXT31VQaLLkCQp7RkKSZrQaisKePiOabzn9ib2HDnN6h3HWPfSCV546QQFuZksmVHDspk1tNSXuP6QJCWBwcFBevv6mTOtItGlSJKU9gyFJKWEWCxGS30JLfUlfOgtrWzf18Pq7cd4/sUOVmw6QkVxLstm1bB0Rg11VQXEDIgkKSHO91+m/9IVypw+JklSwhkKSUo5mRlx5rVUMq+lkvP9l9m0u5M124/zozUH+OHqA5QWZjOrqZxZTeXMnFpOcb6730jSeOl5eTv6YkMhSZISzVBIUkrLy8nkltm13DK7llNnL7J5dyfb9/eyeXcXz714DIApNUXMbCpj9tRyWupLycp0HSJJGiu9w6GQI4UkSUo8QyFJaaOkIJs759dx5/w6BgYG2X+sj+37e9i+r4cnXjjEj9ccJDsrTmgoY9bUMmY1lTO50qlmkjSaDIUkSUoehkKS0lI8HmPa5GKmTS7moVumcr7/MtGhk2zfNxQSff3pbgAqS3K5bU4tt82tpbw4N8FVS9LE13P6AjGgtNBQSJKkRDMUkiSGppnNb6lkfkslAN2nLrB9fw9rdxznsVX7+N6qfcxqKuf2eZOZ31LpFDNJ4y6E8AXgvcBUYE4URdte9f0/Bv7kWt9LJr19/RQXZJOZ4d9RSZISzVBIkq6hoiSXO+ZN5o55k+k8eZ5VWztY9WIHf/vYNgrzslg2q4Y75k6mvrow0aVKSh+PAX8BrHz1N0IIC4FlwIHxLup69fb1O3VMkqQkYSgkSW+gqjSP99wxjXfd1sSO/T08u7WD5RuP8OT6wzTVFnH73MncNKOG/Fz/pEoaO1EUrQIIIfzM8RBCDvDXwIeAFeNe2HXq7eunuiwv0WVIkiQMhSRpxOLxGLOnVTB7WgV95y6yevtxVm49yj8/HvH1p3azKFRz65xJhMZSMuJOi5A0bj4N/EsURftfHRiNVEXF2I16rKoq+pmvT57pZ0Go/rnjqSAV2/RabGtqsq2pK53aa1uvj6GQJL0JRfnZ3LekgXsX17Ovo4+VW4+ydsdxVm8/RlF+FotCNUumVxMaSonH3b1M0tgIIdwMLAb+6408Tnf3GQYGBkenqKtUVRXR2dn3ytfn+y9z9sJlcrPiP3M8Fby6ranMtqYm25q60qm9tvXnxeOx133zx1BIkm5ALPbTXcx+4S2tvLinm3U7T/D8tg5WbDpCcUE2i0IVS0I1bQZEkkbfncAMYN/wKKF64PEQwn+IouiJhFZ2DSfPuB29JEnJxFBIkkZJTlYGi6dXs3h6Nf0Xr/Di3m5e2HmC54bXICouyGZxqGLJ9Gpa6w2IJN24KIo+C3z25a9DCPuBdyTr7mM9fUOhULmhkCRJScFQSJLGQE72zwZEW/Z0sW7nCVZt7eDpjUcoKcxmcVs1dyxuoKYom+ysjESXLCnJhRC+CDwMTAKeDCF0R1E0K8FlXZfe044UkiQpmRgKSdIYy8nO4KYZNdw0o4YLFy+zdU836146wbNbj/LUxsNkZsRpayhh1tRyZjWVU19dSDzmKCJJPyuKok8Cn3yDc6aOTzVvTm/fBcBQSJKkZGEoJEnjKDc785WAqP/iFY739fP85iNs39/Doyv28OiKPRTlZzFzavkrIZEvniSlit6+fgrzssjKdHSkJEnJwFBIkhIkJzuDRdNraKzIB4ZeLO3Y38OO/T1s39/L2h3HAaityH8lIJoxpcypZpImrJ6+ftcTkiQpiRgKSVKSKCvK4dY5tdw6p5bBwUEOd55l+74etu/v4ZktR3lyw2GyM+PMaipnQWsV81oqKMrPTnTZkjRivYZCkiQlFUMhSUpCsViMhupCGqoLuX9pI5cuXyE6dJLNu7vYNPwRi0FrfSkLWitZ0FpJdVl+osuWpNfV29dPc11JosuQJEnDDIUkaQLIysxgdlMFs5sq+PC9bRw43semXV1s2t3JN55u5xtPt1NXVTAcEFUxdVIRMRerlpRELl66wpnzl1wnTZKkJPKGoVAIoQJ4BGgGLgK7gY9HUdT5qvPygX8CFgGXgd+PoujfRr1iSUpzsViMqZOKmTqpmPfcMY0TJ88PjSDa1ckPVx/g354/QFlRDvNbK7l1di1NtQZEkhKv98zQdvROH5MkKXmMZKTQIPC5KIpWAIQQPg98FvjVV533+8DpKIpaQgitwMoQQksURWdGs2BJ0s+qLs3jviUN3LekgTPnL7GlfWh62XNbO1i+8Qh1lQXcNreWm2dNorjANYgkJUbv6aFQyJFCkiQljzcMhaIo6gFWXHVoDfCJa5z6QeBjwz+zO4SwHngAePTGy5QkjURhXtYri1Wfu3CZdTuPs2prB994up1vrdjDvJZKbptby5xp5WTE44kuV1Ia6e0zFJIkKdlc15pCIYQ4Q4HQ96/x7UbgwFVfHwQarufxKyoKr+f061JVVTRmj51sbGvqSqf22tbRMaWhjPfdO52Dx07z5LpDLF9/iI27OikvzuGexY289aZG6qrG7m/vq3ldU1M6tVVvXk/fBcBQSJKkZHK9C03/JXAG+KsxqIXu7jMMDAyO+uNWVRXR2dk36o+bjGxr6kqn9trW0ZeXEeOhZY08sKSerXu6WbW1g+8sb+dbT++mtb6E2+bWsmR6NbnZY7f/gNc1NY20rfF4bEzf/FHy6+3rJz8nc0z/zkiSpOsz4mflEMIXgFbgoSiKBq5xykFgCvDyAtSNwPIbrlCSNGoyM+IsbKtiYVsVJ8/0s3rbMVZu7eCffrSTr/77Lua3VLJ0Zg2zmyrIynR6maTR09vXT1mxo4QkSUomIwqFQgifYWhXsbdHUdT/Gqc9CnwcWD+80PQS4EOjUqUkadSVFubwwLIp3L+0kfYjp1i9/Tjrd57ghZdOkJ+TycJQxdKZNUxvLHX9IUk3rKev36ljkiQlmZFsST8L+ANgF/B8CAFgXxRF7wkhbAYejKLoKPB54MshhHbgCvDrURSlx9h5SZrAYrEYrfWltNaX8otvbWXH/l7W7hgKiFZt7aA4P4sl02tYOrOGaXXFxN3eXtKb0NvXz5QapxBKkpRMRrL72Hbgmq8Aoiiaf9XnZ4H3j15pkqTxlpkRZ25zBXObK7h46Qpb93Sz9qXjPLPlKE9tPExFcQ43zRgKiBqqC4kZEEkagctXBjh99iJlRbmJLkWSJF3Flf4kSdeUnZXB4unVLJ5ezfn+y2za3cnaHSd4Yt0hfrz2INVlecxvqWRecwWtDaVkZjjFTNK1nXQ7ekmSkpKhkCTpDeXlZHLL7FpumV1L37mLbIg62bi7k6c3HuaJdYfIy8lgdlMF81oqmDOtgqL87ESXLCmJ9AyHQuWGQpIkJRVDIUnSdSnKz+auBXXctaCOCxcv89L+Xrbs6WJLezfrdp4gBjTXlTCvpYJ5LZXUVRY4zUxKc72OFJIkKSkZCkmS3rTc7EwWtFWxoK2KgcFBDh7vY0t7N5vbu/j2M3v59jN7qSjOZV5LBXcuamRSSY5b3Utp6KehkGsKSZKUTAyFJEmjIh6LMXVSMVMnFfOu25ro7evnxb3dbGnvYtWLHTy98Qg52RnMaSpnfmslc5srKczLSnTZksZBT98FcrIzyMvJSHQpkiTpKoZCkqQxUVaUwx3zJnPHvMlcunyFoyf7eWb9QTa1d7E+6iQWg9b6Uua3VLKgtZKa8vxElyxpjPT29VNelONUUkmSkoyhkCRpzGVlZrB4Rg1TKvP5pcFBDhzrY/PuLja3d/HN5e18c3k7tRX5zG+pZH5rJc2TS4jHffEopYrevn7XE5IkKQkZCkmSxlU8FqOptpim2mLec8c0uk6dH1qHaHfnK9vdF+VnMWtqOTOnljOrqdwXk9IE19vXz8ypZYkuQ5IkvYqhkCQpoSpL8njLonresqiecxcus23f0ELVO/b1sGbHcQBqK/KHQqKmcqY3lpKb7dOXNFFcGRjg5Jl+F5mWJCkJ2auWJCWN/NxMbppRw00zahgYHOTwiTPs2N/L9v09PLPlKE9uOExGPEbz5GJmNpUza2o5U2uLyIi7o5mUrE6ducjgIJQ74k+SpKRjKCRJSkrxWIzGmiIaa4q4f2kjly5fYffhU2zf38OOfb08tnIfj63cR15OJjOnlLF4ejXzWyvJyXJ3IymZ/HQ7ekMhSZKSjaGQJGn/K6kLAAAOxElEQVRCyMrMYObwOkPcBX3nLvLSgV627+vhxb3dbNjVSU52Bgtbq1g2q4aZU8scQSQlAUMhSZKSl6GQJGlCKsrP/ulUs4FBdh06yZodx1i/s5PV249RnJ/Fkhk1LJtVw7TaYrfClhKkZzgUKi92TSFJkpKNoZAkacKLx2NMn1LG9CllfPjewNY93azdcYxnNh/lqQ2HqS7NY+nMoYCotqIg0eVKaaW37wJZmXEKcu12SpKUbHx2liSllKzMOItCFYtCFecuXGbDrhOs3XGcf1u9nx88v58pk4pYNrOGxaGaihJHLkhjrbevn7KiHEfrSZKUhAyFJEkpKz83k9vnTub2uZM5eaafF3YcZ82O43zj6Xa+8XQ7TbXFLJ5exaJQTXVpXqLLlVJST1+/O49JkpSkDIUkSWmhtDCH+25q5L6bGjnee44NUSfrd57g0eV7eHT5HhprClkcqlk8vZpJ5fmJLldKGb2n+2lrKEl0GZIk6RoMhSRJaaemLJ8Hl03hwWVT6Dp5nvVRJxt2neA7z+7lO8/upb6qgEWhmsWhismVBU57kd6kgYFBTp7pp6zIqZqSJCUjQyFJUlqrLM3j/qWN3L+0kZ7TF9iwq5MNO0/w/VX7+N6qfdRW5LOwrYr5LZU01RYTjxsQSSN16kw/VwYG3Y5ekqQkZSgkSdKw8uJc7l3cwL2LGzh5pp+Nu4ammP14zUF+uPoARflZzJlWwbyWSmZNLSff3ZSk19V16jyAawpJkpSk7M1KknQNpYU53LOwnnsW1nP2wiW27e1hy54utrR38fy2Y2TEY7Q1lDK3eSgkch0i6ed1nbwAQFmxoZAkScnIUEiSpDdQkJvF0pk1LJ1Zw5WBAfYcOc3WPd1s2dP1yk5mNWV5zGupZG5zBbeUGRBJAN3DI4VcU0iSpORkKCRJ0nXIiMdpayilraGU993VTNfJ82zZ083WPd08vfEIT6w7RPybW6guzaOusoDJwx91lQXUlOeTlRlPdBOkcdN18jwZ8RhF+VmJLkWSJF2DoZAkSTegsjSPtyyq5y2L6um/eIUdB3o4fqqf3Qd6ONx1lo27OxkcHDo3HotRXTYUFtUOB0VDn+eTETcsUurpPnWBsqIc4u7gJ0lSUjIUkiRplORkZ7CgtYqqqiI6O/sAuHT5Csd6znOk6wxHu85ytOvcz4VFBbmZzG2uZEFrJbOnlZOb7dOzUkPXqfPuPCZJUhKz1ylJ0hjKysygobqQhurCnzn+clh0uPMM2/b2sHVPF6u3HyMzI8aMKeUsaK1kXkulL6g1oXWfvEBDdUGiy5AkSa/BUEiSpAS4Oiy6edYkrgwM0H74FJt2d7Fpdyf//Hg3PB7RVFvE/JZK5rdWUV9VQMxpOJogBgcH6Tp1nnnNFYkuRZIkvQZDIUmSkkBGPE5oLCM0lvHBe1o42nWWze1dbNrdxXdX7uO7K/dRWZLL/JZKFoUqWutLiccNiJS8zpy/xKXLA452kyQpiRkKSZKUZGKxGHVVhdRVFfL2m6dy6kw/m9u72Ly7i2e2HOXJDYcpzs9iYVsVi6ZXExpKycxwoWoll96+fgBDIUmSkpihkCRJSa6kMIc759dx5/w6Lly8zNY93WyIOlm9/TgrNh+lIDeTBW1VLA5VzJxabkCkpNDzcihUbCgkSVKyMhSSJGkCyc3O5KYZNdw0o4aLl66wbV8P66MTrN95glVbO8jLyWR+SwWLQzWzmsrJzspIdMlKUy+PFCovyk1wJZIk6bUYCkmSNEFlZ2WwsK2KhW1VXLo8wI79QwHR5t1drN5+nJysDOY2VzBjahmhoZRJ5fkuVK1x09t3gXg8RklBdqJLkSRJr8FQSJKkFJCVGWdey9A29pevDLDzYC8bok427+5i3c4TABTnZ9HWUEpbQymhsYy6qgLihkQaI72n+ykvynFBdEmSkpihkCRJKSYzI87spgpmN1Xw0bcNcrz3PLsOnSQ6eJJdh3pZH3UCkJ+TeVVIVEpjTSEZcdcj0ujo6eunojQv0WVIkqTXYSgkSVIKi8ViTCrPZ1J5PnfMmwxA16mhkOjloGhzexcAOdkZLAnV/IcHpzvNTDest6+f5vrSRJchSZJeh6GQJElpprIkj8qSPG6ZXQvAyTP9r4RE8VjMQEij4vZ5tcxsrkp0GZIk6XUYCkmSlOZKC3Ne2dFMGi0PLJ1CVVURnZ19iS5FkiS9BhcOkCRJkiRJSkMjGikUQvgC8F5gKjAniqJt1zjnT4DfBI4OH3ouiqL/NDplSpIkSZIkaTSNdPrYY8BfACvf4Lx/jqLo92+sJEmSJEmSJI21EYVCURStAgghjG01kiRJkiRJGhejvdD0L4QQ7gOOAX8cRdHqUX58SZIkSZIkjYLRDIX+DvjTKIouhRDuBb4XQpgRRVH3SB+goqJwFMv5WVVVRWP22MnGtqaudGqvbU1NtjU1pVNbJUmSUsmohUJRFB276vN/DyEcAmYDz4z0Mbq7zzAwMDhaJb0inbZDta2pK53aa1tTk21NTSNtazweG9M3fyRJknT9Rm1L+hBC3VWfz2dop7JotB5fkiRJkiRJo2ekW9J/EXgYmAQ8GULojqJoVgjhR8AfRVG0HvhMCGERcAW4CHzk6tFDkiRJkiRJSh4j3X3sk8Anr3H8was+/9go1iVJkiRJkqQxNGrTxyRJkiRJkjRxjPaW9JIkSRoDIYQvAO9laN3GOVEUbQshVACPAM0MTd/fDXw8iqLOhBUqSZImDEcKSZIkTQyPAXcAB646Ngh8LoqiEEXRHGAP8NlEFCdJkiYeRwpJkiRNAFEUrQIIIVx9rAdYcdVpa4BPjGthkiRpwkqWUCgDIB6Pjdk/MJaPnWxsa+pKp/ba1tRkW1PTSNp61TkZY1pMGgshxBkKhL5/HT9mH2wU2dbUZFtTUzq1FdKrvbb1Nc+5Zh8sNjg4OIolvWm3ASsTXYQkSRpztwOrEl3ERBZC2A+8I4qiba86/tdAHfBwFEUDI3w4+2CSJKWHa/bBkmWk0DqGCuwAriS4FkmSNPoygFqGnvM1yoYXoW4FHrqOQAjsg0mSlOpetw+WLKFQP75rKElSqtuT6AJSUQjhM8Ai4O1RFPVf54/bB5MkKfW9Zh8sWaaPSZIk6XWEEL4IPAxMArqAbuADwDZgF3B++NR9URS9JyFFSpKkCcVQSJIkSZIkKQ3FE12AJEmSJEmSxp+hkCRJkiRJUhoyFJIkSZIkSUpDhkKSJEmSJElpyFBIkiRJkiQpDWUmuoCxFEJoA74CVDC0betHoyjandiqxk4IYT9wYfgD4P+KoujxhBU0ikIIXwDeC0wF5kRRtG34eMpd49dp635S6PqGECqAR4Bm4CKwG/h4FEWdIYRlwP8H5AH7gV+KouhEomodDW/Q3kHgRWBg+PSPRFH0YmIqHR0hhMeAJobadAb47SiKNqfoPftabd1PCt2zVwsh/DHwJwz/jUrFe1Y3JhXv9deS4ve6/a8UvL7p1Aez/5W6/S9Ivz7YWPW/Un2k0N8Bfx1FURvw1wz9D0t174uiaP7wx4T/xb/KY8AdwIFXHU/Fa/xabYXUur6DwOeiKApRFM0B9gCfDSHEgX8B/tPwdX0W+GwC6xwt12zvVd+/5aprO6E7JMM+FkXRvCiKFgBfAP5x+Hgq3rOv1VZIrXsWgBDCQmAZw3+jUvie1Y1JxXv99aTcvT7M/teQVLu+6dQHs/81JBXvWUijPthY9r9SNhQKIVQDC4GvDR/6GrAwhFCVuKr0ZkVRtCqKokNXH0vVa3yttqaiKIp6oihacdWhNcAUYBFwIYqiVcPH/w74wDiXN+pep70pKYqiU1d9WQIMpPA9+3NtTVQtYy2EkMNQZ/ITVx1OyXtWb16q3uvpyP5XakqnPpj9r9Ttf0H69MHGuv+VsqEQ0AAciaLoCsDwf48OH09lXw0hbA0h/E0IoTTRxYyxdLzGKXl9h5PuTwDfBxq56l26KIq6gHgIoTxB5Y26V7X3ZStCCJtDCP9z+A//hBdC+FII4SDwp8DHSOF79hptfVmq3bOfBv4liqL9Vx1L+XtW1y1l7/XXkWr3+uvx+qaQdOqD2f9KzXs2TfpgY9r/SuVQKB3dHkXRPGAJEAP+KsH1aHSl8vX9S4bmAadSm17Pq9vbGEXRYoaGrc8E/p9EFTaaoij6tSiKGoH/G/h8ousZS6/R1pS6Z0MINwOLgb9JdC1Skkmpe10/J9Wvbzr1wex/paBU74ONR/8rlUOhQ0BdCCEDYPi/k4ePp6SXh7xGUdTP0C/NrYmtaMyl1TVO1es7vLBjK/DBKIoGgINcNaw3hFAJDERR1JOgEkfVNdp79bU9DXyJFLm2L4ui6BHgbuAwKX7PvtzWEEJFCt6zdwIzgH3DCzjWA48DLaTwPas3xefn1Ob1TRHp1Aez/5X692wK98HGvP+VsqFQNLTq9mbgQ8OHPgRsiqKoM3FVjZ0QQkEIoWT48xjwCwy1P2Wl0zVO1esbQvgMQ/Nh3z38RxtgA5AXQrht+OvfAB5NRH2j7VrtDSGUhRDyhj/PBN7HBL+2IYTCEELDVV8/BPQAKXfPvk5bL6TaPRtF0WejKJocRdHUKIqmMtTJfBtD78ql5D2rN8fn54l9r78Rr29qXN906oPZ/0q9/hekTx9sPPpfscHBwVEpNhmFEKYztPVeGdDL0NZ7UWKrGhshhGnAt4GM4Y8dwCejKOpIaGGjJITwReBhYBLQBXRHUTQrFa/xtdoKPESKXd8QwixgG7ALOD98eF8URe8JIdzC0K4Iufx0e8XjCSl0lLxWe4HPMdTWQSALeB74nSiKziSiztEQQqgBvgcUAFcYeoL+/SiKNqbaPftabQVOkmL37KsNv1v1jmhoS9SUu2d1Y1LtXn8t9r9S5/qmS/8L0qsPZv8rNftfkL59sLHof6V0KCRJkiRJkqRrS9npY5IkSZIkSXpthkKSJEmSJElpyFBIkiRJkiQpDRkKSZIkSZIkpSFDIUmSJEmSpDRkKCRJkiRJkpSGDIUkSZIkSZLSkKGQJEmSJElSGvr/AfplfAgDyMOPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 of 40 took 5.165s\n",
      "  training loss (in-iteration): \t1.571384\n",
      "  validation accuracy: \t\t\t21.04 %\n",
      "CPU times: user 3min 24s, sys: 1.96 s, total: 3min 26s\n",
      "Wall time: 3min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "opt = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "train_loss = []\n",
    "val_accuracy = []\n",
    "num_epochs = 40 \n",
    "batch_size = 64  \n",
    "\n",
    "train_loss_epoch=[]\n",
    "val_accuracy_epoch=[]\n",
    "best_val_acc=0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Обучение\n",
    "    model.train(True)\n",
    "    for X_batch, y_batch in iterate_minibatches(X_train, y_train, batch_size, True):\n",
    "        loss=compute_loss(model,X_batch, y_batch)\n",
    "\n",
    "        # делаем backprop\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        train_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    # Валидация\n",
    "    model.train(False)\n",
    "    for X_batch, y_batch in iterate_minibatches(X_val, y_val, batch_size, False):\n",
    "        acc=compute_accuracy(model,X_batch, y_batch)\n",
    "        val_accuracy.append(acc)\n",
    "\n",
    "    train_loss_epoch.append(np.mean(train_loss[-len(X_train) // batch_size :]))\n",
    "    val_acc=np.mean(val_accuracy[-len(X_val) // batch_size :]) * 100\n",
    "    val_accuracy_epoch.append(val_acc)\n",
    "    if best_val_acc<val_acc:\n",
    "            best_val_acc=val_acc\n",
    "            torch.save(model, 'gru_model')\n",
    "\n",
    "    clear_output(True)\n",
    "    fig = plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(train_loss_epoch, label='train')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(val_accuracy_epoch, label='val')\n",
    "    plt.title('Acc')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "        np.mean(train_loss[-len(X_train) // batch_size :])))\n",
    "    print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
    "        np.mean(val_accuracy[-len(X_val) // batch_size :]) * 100))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqnJRr8_QxZM"
   },
   "source": [
    "Не прекрасный результат с точки зрения acc, также видно, что с эпохи 20 модель начала переобучаться, но при этом для простой нейронки очень достойный результат получили"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dt4nSCj7sOz"
   },
   "source": [
    "Напишите функцию, которая по началу высказывания будет генерировать следующие `length_to_predict` символов:\n",
    "* Входной текст приведите к формату, который принимает на вход модель. \n",
    "* Предскажите первый символ. \n",
    "* Предсказаный символ следует добавить в конец текста и полученный текст опять привести к нужному формату. Альтернативно, вы можете прогнать лишь одну ячейку рекуррентной сети, на вход которой подать только что предсказанный символ и в качестве предыдущего скрытого состояния которой взять скрытое состояние полученное на предыдущем шаге.\n",
    "* Затем можно предсказать следующий символ и так далее. \n",
    "\n",
    "\n",
    "*Замечания.*\n",
    "\n",
    "1. Модель принимает объекты батчами, поэтому если вы будете подавать ей один элемент она может ругаться. Один элемент нужно подавать как батч размера 1.\n",
    "\n",
    "2. Для получения предсказания в виде индекса следующего символа нужно найти аргмаксимум по логитам. В этом вам поможет `logits.max(dim)`, который принимает в аргументах размерность `dim` по которой искать максимумы и возвращает сразу 2 тензора — максимумы и индексы максимумов.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vf8J0J2deRMF"
   },
   "source": [
    "Сначала реализуйте жадную генерации текста — на каждом шаге берите токен с наибольшей вероятностью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TXsJey9JsCmz"
   },
   "outputs": [],
   "source": [
    "def simple_predict(model, text, length_to_predict):\n",
    "    #важно не забыть про MAX_LENGTH\n",
    "    bpe_string = bpe.encode(text, output_type=yttm.OutputType.ID, bos=True, eos=False)\n",
    "    start=bpe_string.copy()\n",
    "\n",
    "    len_pad=(MAX_LENGTH-len(bpe_string))\n",
    "    if MAX_LENGTH>len(bpe_string):\n",
    "        bpe_string+=[bpe.subword_to_id('<PAD>')]*(MAX_LENGTH-len(bpe_string))\n",
    "\n",
    "    bpe_string=np.array(bpe_string)\n",
    "    res=[]\n",
    "    log_probs=[]\n",
    "    for i in range(length_to_predict):\n",
    "        #print(bpe_string)\n",
    "        model.train(False)\n",
    "        X_batch=[bpe_string]\n",
    "        X_batch = torch.tensor(X_batch, dtype=torch.int64)\n",
    "        # Логиты, полученные моделью\n",
    "        logp_next,_ = model(X_batch)\n",
    "        p_next = F.softmax(logp_next / 1, dim=-1).data.numpy()[0, -len_pad-1]\n",
    "        index_next=np.argmax(p_next)\n",
    "        res.append(index_next)\n",
    "        log_probs.append(np.max(p_next))\n",
    "        if index_next==bpe.subword_to_id('<EOS>'):\n",
    "            break\n",
    "        \n",
    "        if len_pad>0:\n",
    "            index_first_pad=np.where(bpe_string==pad_idx)[0][0]\n",
    "            bpe_string[index_first_pad]=index_next\n",
    "            len_pad-=1\n",
    "        else:\n",
    "            bpe_string=np.roll(bpe_string, -1)\n",
    "            bpe_string[-1]=index_next\n",
    "\n",
    "    return start+res,log_probs\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5oqJDcZ8RBr"
   },
   "source": [
    "Посмотрим, что предсказывает модель. Не пугайтесь, если будет не много смысла в самих высказываниях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TneSO0UPGYjC"
   },
   "outputs": [],
   "source": [
    "model = torch.load('/content/gru_model')\n",
    "model.train(False)\n",
    "device = torch.device('cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 500,
     "status": "ok",
     "timestamp": 1650649327143,
     "user": {
      "displayName": "Владимир Никитин",
      "userId": "13111598681369803225"
     },
     "user_tz": -180
    },
    "id": "x03u2JPqsGyb",
    "outputId": "cc7bcba4-c2da-44c7-ca1a-d761f4d363c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<BOS> be no mistake about it: \"what is to say, in the same time the<EOS>']"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text, log_probs = simple_predict(model, \"be no mistake about it:\", 50)\n",
    "\n",
    "bpe.decode([(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1650649327144,
     "user": {
      "displayName": "Владимир Никитин",
      "userId": "13111598681369803225"
     },
     "user_tz": -180
    },
    "id": "nIosji1-8V_B",
    "outputId": "b6ad4de6-ca54-443e-bdca-4264db42e6dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<BOS> artificial intelegence is interesting to their own sake, and that they<EOS>']"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text, log_probs = simple_predict(model, \"artificial intelegence is interesting\", 50)\n",
    "\n",
    "bpe.decode([(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 339,
     "status": "ok",
     "timestamp": 1650663984517,
     "user": {
      "displayName": "Владимир Никитин",
      "userId": "13111598681369803225"
     },
     "user_tz": -180
    },
    "id": "Ir4MCMXR8YY8",
    "outputId": "1aa8ee72-c0a0-4016-c334-d0e98f115c0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<BOS> people love ml and the most spiritual fate of authority of the<EOS>']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text, log_probs = simple_predict(model, 'people love ml and', 30)\n",
    "\n",
    "bpe.decode([(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 238,
     "status": "ok",
     "timestamp": 1650662080869,
     "user": {
      "displayName": "Владимир Никитин",
      "userId": "13111598681369803225"
     },
     "user_tz": -180
    },
    "id": "kpQxi10rX65Y",
    "outputId": "168c1f83-6312-4971-f695-b5840b8f029c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFACE\n",
      "\n",
      "\n",
      "SUPPOSING that Truth is a woman--what then? Is there not ground\n",
      "for suspecting that all philosophers, in so far as they have been\n",
      "dogmatists, have failed to understand women--that the terrible\n",
      "seriousness and clumsy importunity with which they have usually paid\n",
      "their addresses to Truth, have been unskilled and unseemly methods for\n",
      "winning a woman? Certainly she has never allowed herself to be won; and\n",
      "at present every kind of dogma stands with sad and discouraged mien--IF,\n"
     ]
    }
   ],
   "source": [
    "!head nietzsche.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lom-35zuWYIp"
   },
   "source": [
    "На самом деле с генерацией довольно много нюансов происходит, а именно: 1) есть несколько способом генерации предложений, мы можем давать предложение и каждый раз давать модели все более длинное и длинное предложение, или мы можем давать по одному слову. В данном случае 1 вариант более предпочительный в отличии от задачи генерации имен на семинаре, так как тут мы работает с батчами+мы не делаем np.random.choice. \n",
    "2) Изначально у меня были проблемы с зацикливанием, но улучшив метрику модели я смог отчасти избавиться от данной проблемы, но зато у меня появилась новая, а именно \"любовь ставить EOS\". На самом деле это проблема появляется из-за формата данных, которые поступают нам, давайте внимательно посмотрим, становится понятно, что нам поступают строчки, а не предложения. То есть мы учимся на тексте, где оч часто встречается незаконченная мысль (именно этот результат видим после генерации текста).\n",
    "3)**Сам вывод** на самом деле текст получился довольно хорошим и даже слегка логичным по тексту, видно, что вставлялись не рандомные токены. \n",
    "a)be no mistake about it: \"what is to say, in the same time the\n",
    "не заблуждайтесь на этот счет: \"что сказать, в то же время\n",
    "\n",
    "b)artificial intelegence is interesting to their own sake, and that they\n",
    "искусственный интеллект интересен сам по себе, и что они\n",
    "\n",
    "c)people love ml and the most spiritual fate of authority of the\n",
    "люди любят мл и самую духовную судьбу власти в\n",
    "\n",
    "Но при этом все равно очевидна нам неидеальность и довольно среднее качество данных результатов, модель можно было сделать более сложной, добавить больше слоев, но координальным решением наших проблем было бы использование Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFtp-0MTcysK"
   },
   "source": [
    "Жадная генерация не самая хорошая. Возможно ваши предсказания зациклились. Это связано с тем, что \n",
    "1. Модель в основном смотрит лишь на последние несколько токенов при предсказании следующего.\n",
    "\n",
    "2. При предсказании модель генерирует жадно и максимизирует вероятность только одного следующего токена, не думая про то, что может быть дальше.\n",
    "\n",
    "3. Модель была обучена максимизировать правдоподобие и генерировать токены смотря лишь на предыдущие токены. Из этого модель сильно теряет в разнообразии и может получится так, что модель найдет некоторые часто повторяющиеся структуры в датасете и будет присваивать им большую вероятность. \n",
    "\n",
    "Для решения этой проблемы существует несколько методов. Одни из них:\n",
    "\n",
    "* Top k sampling \n",
    "\n",
    "  Для предсказания следующего токена посмотрим на  распределение вероятностей на следующий токен. Выбираем $k$ токенов с максимальной вероятностью и из них сэмплируем один токен с вероятностью пропорциональной предсказанной для этого токена вероятности.\n",
    "\n",
    "* Beam-search\n",
    "\n",
    "\n",
    "\\\\\n",
    "\n",
    "**Реализуйте один из подходов.** \n",
    "\n",
    "* Top k sampling (1 балл)\n",
    "\n",
    "* Beam-search (3 балла)\n",
    "\n",
    "Учитывайте, что реализовать beam-search намного сложнее, чем top k sampling, поэтому за его реализацию дается больше баллов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4WYhgeLiuo3x"
   },
   "outputs": [],
   "source": [
    "def vector_prob(model,bpe_string,len_pad):\n",
    "  model.train(False)\n",
    "  X_batch=[bpe_string]\n",
    "  X_batch = torch.tensor(X_batch, dtype=torch.int64)\n",
    "  # Логиты, полученные моделью\n",
    "  logp_next,_ = model(X_batch)\n",
    "  p_next = F.softmax(logp_next / 1, dim=-1).data.numpy()[0, -len_pad-1]\n",
    "  return p_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K4gryi7egkrt"
   },
   "outputs": [],
   "source": [
    "beam = 30\n",
    "\n",
    "\n",
    "def predict(model, text, length_to_predict):\n",
    "    bpe_string = bpe.encode(text, output_type=yttm.OutputType.ID, bos=True, eos=False)\n",
    "    start = bpe_string.copy()\n",
    "\n",
    "    len_pad = (MAX_LENGTH - len(bpe_string))\n",
    "    if MAX_LENGTH > len(bpe_string):\n",
    "        bpe_string += [bpe.subword_to_id('<PAD>')] * (MAX_LENGTH - len(bpe_string))\n",
    "\n",
    "    bpe_string = np.array(bpe_string)\n",
    "    tree = {}\n",
    "    index_tree = set([0])\n",
    "    tree[0] = [bpe_string, len_pad, 1, False, []]\n",
    "    # в таком формате мы будем хранить узел, мб было легче структуру Node написать\n",
    "    # [bre_sting,len_pad, вероятность данной ветви,был ли eos уже,res]\n",
    "    for i in range(length_to_predict):\n",
    "        index_tree_list = list(index_tree)\n",
    "        for j in index_tree_list:\n",
    "          #перебираем узлы\n",
    "            array=tree[j].copy()\n",
    "            bpe_string, len_pad, prob_last, status, res = array\n",
    "            if status == True:\n",
    "                continue\n",
    "            prob = vector_prob(model, bpe_string, len_pad)\n",
    "            index = np.argsort(prob)[-beam:]\n",
    "            prob = np.array(prob)[index]\n",
    "\n",
    "            # теперь нам надо данный узел разветвить\n",
    "            if len_pad > 0:\n",
    "                len_pad -= 1\n",
    "            for k in range(beam):\n",
    "                bpe_string_copy=bpe_string.copy()\n",
    "\n",
    "                number = max(index_tree) + 1\n",
    "                index_tree.add(number)\n",
    "\n",
    "                index_next = index[k]\n",
    "                prob_now = prob[k]\n",
    "                res_local = res.copy()\n",
    "                res_local.append(index_next)\n",
    "                if index_next == bpe.subword_to_id('<EOS>'):\n",
    "                    tree[number] = [bpe_string_copy, len_pad, prob_now * prob_last, True, res_local]\n",
    "                    continue\n",
    "                elif len_pad >= 0:\n",
    "                    index_first_pad = np.where(bpe_string == pad_idx)[0][0]\n",
    "                    bpe_string_copy[index_first_pad] = index_next\n",
    "                else:\n",
    "                    bpe_string_copy = np.roll(bpe_string, -1)\n",
    "                    bpe_string_copy[-1] = index_next\n",
    "                tree[number] = [bpe_string_copy, len_pad, prob_now * prob_last, False, res_local]\n",
    "\n",
    "            index_tree.discard(j)\n",
    "            tree.pop(j, None)\n",
    "\n",
    "        # осталось совсем немного\n",
    "        # очень важная часть кода, а именно удаление неоптимальных ветвей нашего дерева\n",
    "        index_tree_list = list(index_tree)\n",
    "\n",
    "        if len(index_tree_list) <= beam:\n",
    "            continue\n",
    "        dict_number_prob = {j: tree[j][2] for j in index_tree_list}\n",
    "      \n",
    "        sorted_tuples = sorted(tree.items(), key=lambda item: item[1][2], reverse=True)\n",
    "        sorted_tuples = sorted_tuples[beam:]\n",
    "        for tuple_now in sorted_tuples:\n",
    "            index_tree.discard(tuple_now[0])\n",
    "            tree.pop(tuple_now[0], None)\n",
    "\n",
    "    # теперь нам выбрать самый вероятный путь и его вывести\n",
    "    index_tree_list = list(index_tree)\n",
    "    dict_number_prob = {j: tree[j][2] for j in index_tree_list}\n",
    "    sorted_tuples = sorted(tree.items(), key=lambda item: item[1][2],reverse=True)\n",
    "    best_index = sorted_tuples[0][0]\n",
    "    return start+tree[best_index][4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8147,
     "status": "ok",
     "timestamp": 1650663807119,
     "user": {
      "displayName": "Владимир Никитин",
      "userId": "13111598681369803225"
     },
     "user_tz": -180
    },
    "id": "PhJ55XwAOjmz",
    "outputId": "89c8ccd4-34b4-49b8-ba07-7d97508d93de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<BOS> be no mistake about it: \"beyond good and evil.\"<EOS>']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text= predict(model, \"be no mistake about it:\", 50)\n",
    "\n",
    "bpe.decode([(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5436,
     "status": "ok",
     "timestamp": 1650663824962,
     "user": {
      "displayName": "Владимир Никитин",
      "userId": "13111598681369803225"
     },
     "user_tz": -180
    },
    "id": "QVMA58o7Ojm1",
    "outputId": "919ead1a-0fd5-4aff-8197-92c2005c8d36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<BOS> artificial intelegence is interesting themselves.<EOS>']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text= predict(model, \"artificial intelegence is interesting\", 50)\n",
    "\n",
    "bpe.decode([(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9970,
     "status": "ok",
     "timestamp": 1650663984182,
     "user": {
      "displayName": "Владимир Никитин",
      "userId": "13111598681369803225"
     },
     "user_tz": -180
    },
    "id": "uQshPafdOjm1",
    "outputId": "f495b70d-f8f3-4319-c590-fe61f2558ca8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<BOS> people love ml and that is to say, that is to say, as the<EOS>']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text= predict(model, 'people love ml and', 30)\n",
    "\n",
    "bpe.decode([(text)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLVfdp4RPcKi"
   },
   "source": [
    "Получили прекрасный результат, получили уже даже понятный текст по смыслу, особенно прекрасен второй текст artificial intelegence is interesting themselves. искусственный интеллект интересен сам по себе.\n",
    "\n",
    "\n",
    "people love ml and that is to say, that is to say, as the=люди любят ml, и это означает, что, то есть, как. (слегка незаконченная мысль).\n",
    "\n",
    "\n",
    "be no mistake about it: \"beyond good and evil.\"=не заблуждайтесь на этот счет: \"по ту сторону добра и зла\". (филофская мысль, очень подходит под произведение)\n",
    "\n",
    "Получили намного лучше результат, прям радует глаза логичные тексты, но также есть недостаток, что слегка рано eos, но это так как текст поступает нам по строчкам и в нем часто есть незаконченные предложения, в идеале нам конечно давали бы предложения, которые заканичваются обычным знаком препинания.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMOQ_maBr9t5"
   },
   "source": [
    "### **Дополнительная информация**\n",
    "\n",
    "[Статья](https://www.aclweb.org/anthology/P19-1365.pdf) с ACL 2019 про сравнение различных методов декодирования."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nlp2_statement_Nikitin.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
