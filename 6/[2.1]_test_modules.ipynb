{"cells":[{"cell_type":"markdown","metadata":{"id":"rXa3YaavIGBg"},"source":["# Машинное обучение, DS-поток\n","## Домашнее задание 1.6\n","\n","---\n","\n","См. сначала **`[0.1]_train_model.ipynb`**, в котором описана структура этого задания.  \n","\n","Перед выполнением этого ноутбука нужно реализовать все слои в **`[1.1]_modules.ipynb`**.  \n","\n","Если все тесты в этом ноутбуке пройдены, то можно приступать к выполнению **`[0.1]_train_model.ipynb`** для тестирования нейросети на датасетах."]},{"cell_type":"markdown","metadata":{"id":"GdM3pOoGIGBm"},"source":["## Тестирование"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4vt8Oa7zrz5S","executionInfo":{"status":"ok","timestamp":1647589704220,"user_tz":-180,"elapsed":2660,"user":{"displayName":"Владимир Георгиевич Никитин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14120092717544999454"}},"outputId":"e32b3587-95e6-4497-9f2f-abab9a9576a1"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["path_to_modules_notebook='/content/drive/MyDrive/Colab_Notebooks/DS/ML/6_ДЗ/[1.1]_modules.ipynb'"],"metadata":{"id":"XvZ4bel1r-o5","executionInfo":{"status":"ok","timestamp":1647589704221,"user_tz":-180,"elapsed":5,"user":{"displayName":"Владимир Георгиевич Никитин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14120092717544999454"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","execution_count":75,"metadata":{"id":"jxZin7tfIGBn","executionInfo":{"status":"ok","timestamp":1647589705832,"user_tz":-180,"elapsed":1615,"user":{"displayName":"Владимир Георгиевич Никитин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14120092717544999454"}}},"outputs":[],"source":["%run $path_to_modules_notebook"]},{"cell_type":"code","execution_count":76,"metadata":{"id":"esgLnty_IGBo","executionInfo":{"status":"ok","timestamp":1647589705833,"user_tz":-180,"elapsed":8,"user":{"displayName":"Владимир Георгиевич Никитин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14120092717544999454"}}},"outputs":[],"source":["import torch\n","import numpy as np\n","import unittest"]},{"cell_type":"code","execution_count":77,"metadata":{"id":"Z4u5k3EGIGBp","executionInfo":{"status":"ok","timestamp":1647589705833,"user_tz":-180,"elapsed":7,"user":{"displayName":"Владимир Георгиевич Никитин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14120092717544999454"}}},"outputs":[],"source":["RANDOM_SEED = 42"]},{"cell_type":"markdown","metadata":{"id":"lE0zCZ_WIGBp"},"source":["*Примечание:* Если тестирование линейного слоя по каким-либо техническим причинам не работает, то рекомендуем использовать Google Colab для запуска этого ноутбука. Известны случаи, когдя ядро ноутбука \"умирает\" из-за этого теста."]},{"cell_type":"code","execution_count":78,"metadata":{"code_folding":[],"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1813,"status":"ok","timestamp":1647589707640,"user":{"displayName":"Владимир Георгиевич Никитин","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14120092717544999454"},"user_tz":-180},"id":"PvLUMW_YIGBq","outputId":"20db89f5-72b4-4e1e-db91-c4ea5834021d"},"outputs":[{"output_type":"stream","name":"stderr","text":["test_BatchNormalization (__main__.TestLayers) ... ok\n","test_Dropout (__main__.TestLayers) ... ok\n","test_LeakyReLU (__main__.TestLayers) ... ok\n","test_Linear (__main__.TestLayers) ... ok\n","test_LogSoftMax (__main__.TestLayers) ... ok\n","test_NLLCriterion (__main__.TestLayers) ... ok\n","test_NLLCriterionUnstable (__main__.TestLayers) ... ok\n","test_ReLU (__main__.TestLayers) ... ok\n","test_Sequential (__main__.TestLayers) ... ok\n","test_SoftMax (__main__.TestLayers) ... ok\n","\n","----------------------------------------------------------------------\n","Ran 10 tests in 0.636s\n","\n","OK\n"]},{"output_type":"execute_result","data":{"text/plain":["<unittest.runner.TextTestResult run=10 errors=0 failures=0>"]},"metadata":{},"execution_count":78}],"source":["class TestLayers(unittest.TestCase):\n","    '''\n","        Класс для тестирования всех модулей.\n","    '''\n","    \n","    def _generate_test_data(\n","        self, shape, dtype=np.float32, mode='uniform', minval=-10, maxval=10\n","    ):\n","        '''\n","        Генерирует тестовые данные для `forward()` и `backward()`\n","        '''\n","        if mode == 'uniform':\n","            rand_array = np.random.uniform(minval, maxval, shape).astype(dtype)\n","            # иногда имеет смысл нормализовать\n","            # rand_array /= rand_array.sum(axis=-1, keepdims=True)\n","            # rand_array = rand_array.clip(1e-5, 1.)\n","            # rand_array = 1. / rand_array\n","            return rand_array\n","    \n","    \n","    def _custom_forward_backward(\n","        self, \n","        layer_input, \n","        next_layer_grad,\n","        custom_layer,\n","        return_params_grad=False\n","    ):\n","        '''\n","        Вычисляет результат `forward()` и `backward()` в слое `layer`.\n","        \n","        Вход:\n","            `layer_input (np.array)` -- тестовый вход\n","            `next_layer_grad (np.array)` -- тестовый градиент, \n","                пришедший от следующего слоя \n","            `layer` -- слой из нашего мини-фреймворка на NumPy\n","            `return_params_grad` -- если True, то вернуть еще градиенты параметров слоя\n","        Выход:\n","            `custom_layer_output (np.array)` -- выход слоя `layer` после `forward()`\n","            `custom_layer_grad (np.array)` -- градиент слоя `layer` после `backward()`\n","            [opt] `custom_params_grad (np.array)` -- градиенты параметров слоя `layer`\n","        '''\n","        custom_layer_output = custom_layer.forward(layer_input)\n","        custom_layer_grad = custom_layer.backward(layer_input, next_layer_grad)\n","        if return_params_grad:\n","            custom_layer.update_grad_params(layer_input, next_layer_grad)\n","            custom_params_grad = custom_layer.get_grad_params()\n","            return custom_layer_output, custom_layer_grad, custom_params_grad\n","        else:\n","            return custom_layer_output, custom_layer_grad\n","    \n","    \n","    def _torch_forward_backward(\n","        self, \n","        layer_input, \n","        next_layer_grad, \n","        torch_layer,\n","        return_params_grad=False\n","    ):\n","        '''\n","        Вычисляет результат `forward()` и `backward()` в PyTorch-слое `layer`.\n","        \n","        Вход:\n","            `layer_input (np.array)` -- тестовый вход\n","            `next_layer_grad (np.array)` -- тестовый градиент, \n","                пришедший от следующего слоя \n","            `torch_layer` -- слой из PyTorch\n","            `return_params_grad` -- если True, то вернуть еще градиенты параметров слоя\n","        Выход:\n","            `torch_layer_output (np.array)` -- выход слоя `layer` после `forward()`\n","            `torch_layer_grad (np.array)` -- градиент слоя `layer` после `backward()`\n","            [opt] `torch_params_grad (np.array)` -- градиенты параметров слоя `layer`\n","        '''\n","        layer_input_torch = torch.from_numpy(layer_input)\n","        layer_input_torch.requires_grad = True\n","        torch_layer_output = torch_layer(layer_input_torch)\n","        torch_layer_output = torch_layer_output\n","        next_layer_grad_torch = torch.from_numpy(next_layer_grad)\n","        torch_layer_output.backward(next_layer_grad_torch)\n","        torch_layer_grad = layer_input_torch.grad\n","        if return_params_grad:\n","            torch_params_grad = torch_layer.parameters()\n","            return torch_layer_output.data.numpy(), torch_layer_grad.data.numpy(), torch_params_grad\n","        else:\n","            return torch_layer_output.data.numpy(), torch_layer_grad.data.numpy()\n","    \n","    \n","    def test_Linear(self):\n","        np.random.seed(RANDOM_SEED)\n","        torch.manual_seed(RANDOM_SEED)\n","        batch_size, n_in, n_out = 2, 3, 4\n","        for _ in range(100):\n","            # инициализируем слои\n","            torch_layer = torch.nn.Linear(n_in, n_out)\n","            custom_layer = Linear(n_in, n_out)\n","            custom_layer.W = torch_layer.weight.data.numpy().T\n","            custom_layer.b = torch_layer.bias.data.numpy()\n","            # формируем тестовые входные тензоры\n","            layer_input = self._generate_test_data((batch_size, n_in))\n","            next_layer_grad = self._generate_test_data((batch_size, n_out))\n","            # тестируем наш слой\n","            result = self._custom_forward_backward(\n","                layer_input,\n","                next_layer_grad,\n","                custom_layer,\n","                return_params_grad=True\n","            )\n","            custom_layer_output, custom_layer_grad, custom_params_grad = result\n","            # тестируем слой на PyTorch\n","            result = self._torch_forward_backward(\n","                layer_input,\n","                next_layer_grad,\n","                torch_layer,\n","                return_params_grad=True\n","            )\n","            torch_layer_output, torch_layer_grad, torch_params_grad = result\n","            # сравниваем выходы с точностью atol\n","            self.assertTrue(np.allclose(torch_layer_output, custom_layer_output, atol=1e-6))\n","            self.assertTrue(np.allclose(torch_layer_grad, custom_layer_grad, atol=1e-6))\n","            weight_grad, bias_grad = custom_params_grad\n","            torch_weight_grad = torch_layer.weight.grad.data.numpy()\n","            torch_bias_grad = torch_layer.bias.grad.data.numpy()\n","            self.assertTrue(np.allclose(torch_weight_grad.T, weight_grad, atol=1e-6))\n","            self.assertTrue(np.allclose(torch_bias_grad, bias_grad, atol=1e-6))\n","            \n","    \n","    def test_SoftMax(self):\n","        np.random.seed(RANDOM_SEED)\n","        torch.manual_seed(RANDOM_SEED)\n","        batch_size, n_in = 2, 4\n","        for _ in range(100):\n","            # инициализируем слои\n","            custom_layer = LogSoftMax()\n","            torch_layer = torch.nn.LogSoftmax(dim=1)\n","            # формируем тестовые входные тензоры\n","            layer_input = self._generate_test_data((batch_size, n_in))\n","            next_layer_grad = self._generate_test_data((batch_size, n_in))\n","            # тестируем наш слой\n","            custom_layer_output, custom_layer_grad = self._custom_forward_backward(\n","                layer_input,\n","                next_layer_grad,\n","                custom_layer\n","            )\n","            # тестируем слой на PyTorch\n","            torch_layer_output, torch_layer_grad = self._torch_forward_backward(\n","                layer_input,\n","                next_layer_grad,\n","                torch_layer\n","            )\n","            # сравниваем выходы с точностью atol\n","            self.assertTrue(np.allclose(custom_layer_output, torch_layer_output, atol=1e-5))\n","            self.assertTrue(np.allclose(custom_layer_grad, torch_layer_grad, atol=1e-5))\n","            \n","            \n","    def test_LogSoftMax(self):\n","        np.random.seed(RANDOM_SEED)\n","        torch.manual_seed(RANDOM_SEED)\n","        batch_size, n_in = 2, 4\n","        for _ in range(100):\n","            # инициализируем слои\n","            custom_layer = LogSoftMax()\n","            torch_layer = torch.nn.LogSoftmax(dim=1)\n","            # формируем тестовые входные тензоры\n","            layer_input = self._generate_test_data((batch_size, n_in))\n","            next_layer_grad = self._generate_test_data((batch_size, n_in))\n","            # тестируем наш слой\n","            custom_layer_output, custom_layer_grad = self._custom_forward_backward(\n","                layer_input,\n","                next_layer_grad,\n","                custom_layer\n","            )\n","            # тестируем слой на PyTorch\n","            torch_layer_output, torch_layer_grad = self._torch_forward_backward(\n","                layer_input,\n","                next_layer_grad,\n","                torch_layer\n","            )\n","            # сравниваем выходы с точностью atol\n","            self.assertTrue(np.allclose(custom_layer_output, torch_layer_output, atol=1e-5))\n","            self.assertTrue(np.allclose(custom_layer_grad, torch_layer_grad, atol=1e-5))\n","\n","            \n","    def test_BatchNormalization(self):\n","        np.random.seed(RANDOM_SEED)\n","        torch.manual_seed(RANDOM_SEED)\n","        batch_size, n_in = 32, 16\n","        for _ in range(100):\n","            # инициализируем слои\n","            slope = np.random.uniform(0.01, 0.05)\n","            alpha = 0.9\n","            custom_layer = BatchNormalization(alpha)\n","            custom_layer.train()\n","            torch_layer = torch.nn.BatchNorm1d(\n","                num_features=n_in, \n","                eps=custom_layer.EPS, \n","                momentum=1.-alpha, \n","                affine=False\n","            )\n","            custom_layer.moving_mean = torch_layer.running_mean.numpy().copy()\n","            custom_layer.moving_variance = torch_layer.running_var.numpy().copy()\n","            # формируем тестовые входные тензоры\n","            layer_input = self._generate_test_data((batch_size, n_in))\n","            next_layer_grad = self._generate_test_data((batch_size, n_in))\n","            # тестируем наш слой\n","            custom_layer_output, custom_layer_grad = self._custom_forward_backward(\n","                layer_input,\n","                next_layer_grad,\n","                custom_layer,\n","                return_params_grad=False\n","            )\n","            # тестируем слой на PyTorch\n","            torch_layer_output, torch_layer_grad = self._torch_forward_backward(\n","                layer_input,\n","                next_layer_grad,\n","                torch_layer,\n","                return_params_grad=False\n","            )\n","            # сравниваем выходы с точностью atol\n","            self.assertTrue(np.allclose(torch_layer_output, custom_layer_output, atol=1e-6))\n","            self.assertTrue(np.allclose(torch_layer_grad, custom_layer_grad, atol=1e-4))\n","            # тестируем moving mean\n","            self.assertTrue(np.allclose(custom_layer.moving_mean, torch_layer.running_mean.numpy()))\n","            # мы не проверяем moving variance, потому что в PyTorch используется \n","            # немного другая формула: var * N / (N-1) (несмещенная оценка)\n","#             self.assertTrue(np.allclose(custom_layer.moving_variance, torch_layer.running_var.numpy()))\n","            # тестируем BatchNorm на стадии evaluation\n","            custom_layer.moving_variance = torch_layer.running_var.numpy().copy()\n","            custom_layer.evaluate()\n","            torch_layer.eval()\n","            custom_layer_output, custom_layer_grad = self._custom_forward_backward(\n","                layer_input,\n","                next_layer_grad,\n","                custom_layer,\n","                return_params_grad=False\n","            )\n","            torch_layer_output, torch_layer_grad = self._torch_forward_backward(\n","                layer_input,\n","                next_layer_grad,\n","                torch_layer,\n","                return_params_grad=False\n","            )\n","            self.assertTrue(np.allclose(torch_layer_output, custom_layer_output, atol=1e-6))\n","            \n","            \n","    def test_Sequential(self):\n","        np.random.seed(RANDOM_SEED)\n","        torch.manual_seed(RANDOM_SEED)\n","        batch_size, n_in = 2, 4\n","        for _ in range(100):\n","            # инициализируем слои\n","            alpha = 0.9\n","            # тестируем `Sequential = [BatchNormalization, Scaling]`,\n","            # чтобы убедиться, что он равен `BatchNorm1d` из PyTorch\n","            # torch слой\n","            torch_layer = torch.nn.BatchNorm1d(\n","                n_in, eps=BatchNormalization.EPS, momentum=1.-alpha, affine=True\n","            )\n","            torch_layer.bias.data = torch.from_numpy(np.random.random(n_in).astype(np.float32))\n","            # наши слои\n","            custom_layer = Sequential()\n","            bn_layer = BatchNormalization(alpha)\n","            bn_layer.moving_mean = torch_layer.running_mean.numpy().copy()\n","            bn_layer.moving_variance = torch_layer.running_var.numpy().copy()\n","            custom_layer.add(bn_layer)\n","            scaling_layer = Scaling(n_in)\n","            scaling_layer.gamma = torch_layer.weight.data.numpy()\n","            scaling_layer.beta = torch_layer.bias.data.numpy()\n","            custom_layer.add(scaling_layer)\n","            custom_layer.train()\n","            # формируем тестовые входные тензоры\n","            layer_input = self._generate_test_data((batch_size, n_in), minval=-5, maxval=5)\n","            next_layer_grad = self._generate_test_data((batch_size, n_in), minval=-5, maxval=5)\n","            # тестируем наш слой\n","            result = self._custom_forward_backward(\n","                layer_input,\n","                next_layer_grad,\n","                custom_layer,\n","                return_params_grad=True\n","            )\n","            custom_layer_output, custom_layer_grad, custom_params_grad = result\n","            # тестируем слой на PyTorch\n","            result = self._torch_forward_backward(\n","                layer_input,\n","                next_layer_grad,\n","                torch_layer,\n","                return_params_grad=True\n","            )\n","            torch_layer_output, torch_layer_grad, torch_params_grad = result\n","            # сравниваем выходы с точностью atol\n","            self.assertTrue(np.allclose(torch_layer_output, custom_layer_output, atol=1e-4))\n","            self.assertTrue(np.allclose(torch_layer_grad, custom_layer_grad, atol=1e-4))\n","            weight_grad, bias_grad = custom_params_grad[1]\n","            torch_weight_grad = torch_layer.weight.grad.data.numpy()\n","            torch_bias_grad = torch_layer.bias.grad.data.numpy()\n","            self.assertTrue(np.allclose(torch_weight_grad, weight_grad, atol=1e-4))\n","            self.assertTrue(np.allclose(torch_bias_grad, bias_grad, atol=1e-4))\n","\n","            \n","    def test_Dropout(self):\n","        np.random.seed(RANDOM_SEED)\n","        batch_size, n_in = 2, 4\n","        for _ in range(100):\n","            # инициализируем слой\n","            p = np.random.uniform(0.3, 0.7)\n","            layer = Dropout(p)\n","            layer.train()\n","            # формируем тестовые входные тензоры\n","            layer_input = self._generate_test_data((batch_size, n_in), minval=-5, maxval=5)\n","            next_layer_grad = self._generate_test_data((batch_size, n_in), minval=-5, maxval=5)\n","            # тестируем `update_output()`\n","            layer_output = layer.update_output(layer_input)\n","            self.assertTrue(np.all(np.logical_or(\n","                np.isclose(layer_output, 0), \n","                np.isclose(layer_output*(1.-p), layer_input)\n","            )))\n","            # тестируем `update_grad_input()`\n","            layer_grad = layer.update_grad_input(layer_input, next_layer_grad)\n","            self.assertTrue(np.all(np.logical_or(\n","                np.isclose(layer_grad, 0), \n","                np.isclose(layer_grad*(1.-p), next_layer_grad)\n","            )))\n","            # тестируем evaluation режим\n","            layer.evaluate()\n","            layer_output = layer.update_output(layer_input)\n","            self.assertTrue(np.allclose(layer_output, layer_input))\n","            # тетсируем маску при нескольких значениях `p`\n","            p = 0.0\n","            layer = Dropout(p)\n","            layer.train()\n","            layer_output = layer.update_output(layer_input)\n","            self.assertTrue(np.allclose(layer_output, layer_input))\n","            p = 0.5\n","            layer = Dropout(p)\n","            layer.train()\n","            layer_input = self._generate_test_data((batch_size, n_in), minval=-5, maxval=5)\n","            next_layer_grad = self._generate_test_data((batch_size, n_in), minval=-5, maxval=5)\n","            layer_output = layer.update_output(layer_input)\n","            zeroed_elem_mask = np.isclose(layer_output, 0)\n","            layer_grad = layer.update_grad_input(layer_input, next_layer_grad)        \n","            self.assertTrue(np.all(zeroed_elem_mask == np.isclose(layer_grad, 0)))\n","            # тестируем тот факт, что маска должна генерироваться независимо\n","            # для каждого элемента входной матрицы, а не для строки/столбца\n","            batch_size, n_in = 1000, 1\n","            p = 0.8\n","            layer = Dropout(p)\n","            layer.train()\n","            layer_input = self._generate_test_data((batch_size, n_in), minval=5, maxval=10)\n","            layer_output = layer.update_output(layer_input)\n","            self.assertTrue(np.sum(np.isclose(layer_output, 0)) != layer_input.size)\n","            layer_input = layer_input.T\n","            layer_output = layer.update_output(layer_input)\n","            self.assertTrue(np.sum(np.isclose(layer_output, 0)) != layer_input.size)\n","    \n","    \n","    def test_ReLU(self):\n","        np.random.seed(RANDOM_SEED)\n","        torch.manual_seed(RANDOM_SEED)\n","        batch_size, n_in = 2, 4\n","        for _ in range(100):\n","            # инициализируем слои\n","            custom_layer = ReLU()\n","            torch_layer = torch.nn.ReLU()\n","            # формируем тестовые входные тензоры\n","            layer_input = self._generate_test_data((batch_size, n_in))\n","            next_layer_grad = self._generate_test_data((batch_size, n_in))\n","            # тестируем наш слой\n","            custom_layer_output, custom_layer_grad = self._custom_forward_backward(\n","                layer_input,\n","                next_layer_grad,\n","                custom_layer\n","            )\n","            # тестируем слой на PyTorch\n","            torch_layer_output, torch_layer_grad = self._torch_forward_backward(\n","                layer_input,\n","                next_layer_grad,\n","                torch_layer\n","            )\n","            # сравниваем выходы с точностью atol\n","            self.assertTrue(np.allclose(custom_layer_output, torch_layer_output, atol=1e-6))\n","            self.assertTrue(np.allclose(custom_layer_grad, torch_layer_grad, atol=1e-6))\n","    \n","            \n","    def test_LeakyReLU(self):\n","        np.random.seed(RANDOM_SEED)\n","        torch.manual_seed(RANDOM_SEED)\n","        batch_size, n_in = 2, 4\n","        for _ in range(100):\n","            # инициализируем слои\n","            slope = np.random.uniform(0.01, 0.05)\n","            torch_layer = torch.nn.LeakyReLU(slope)\n","            custom_layer = LeakyReLU(slope)\n","            # формируем тестовые входные тензоры\n","            layer_input = self._generate_test_data((batch_size, n_in))\n","            next_layer_grad = self._generate_test_data((batch_size, n_in))\n","            # тестируем наш слой\n","            custom_layer_output, custom_layer_grad = self._custom_forward_backward(\n","                layer_input,\n","                next_layer_grad,\n","                custom_layer\n","            )\n","            # тестируем слой на PyTorch\n","            torch_layer_output, torch_layer_grad = self._torch_forward_backward(\n","                layer_input,\n","                next_layer_grad,\n","                torch_layer\n","            )\n","            # сравниваем выходы с точностью atol\n","            self.assertTrue(np.allclose(custom_layer_output, torch_layer_output, atol=1e-6))\n","            self.assertTrue(np.allclose(custom_layer_grad, torch_layer_grad, atol=1e-6))\n","            \n","    def test_NLLCriterionUnstable(self):\n","        np.random.seed(RANDOM_SEED)\n","        torch.manual_seed(RANDOM_SEED)\n","        batch_size, n_in = 2, 4\n","        for _ in range(100):\n","            # инициализируем слои\n","            torch_layer = torch.nn.NLLLoss()\n","            custom_layer = NLLCriterionUnstable()\n","            # формируем тестовые данные\n","            layer_input = np.random.uniform(0, 1, (batch_size, n_in)).astype(np.float32)\n","            layer_input /= layer_input.sum(axis=-1, keepdims=True)\n","            layer_input = layer_input.clip(custom_layer.EPS, 1.-custom_layer.EPS)\n","            target_labels = np.random.choice(n_in, batch_size)\n","            target = np.zeros((batch_size, n_in), np.float32)\n","            target[np.arange(batch_size), target_labels] = 1\n","            # тестируем `update_output()`\n","            custom_layer_output = custom_layer.update_output(layer_input, target)\n","            layer_input_var = torch.from_numpy(layer_input)\n","            layer_input_var.requires_grad = True\n","            torch_layer_output_var = torch_layer(\n","                torch.log(layer_input_var), torch.from_numpy(target_labels).long())\n","            self.assertTrue(np.allclose(\n","                torch_layer_output_var.data.numpy(), custom_layer_output, atol=1e-6\n","            ))\n","            # тестируем `update_grad_input()`\n","            custom_layer_grad = custom_layer.update_grad_input(layer_input, target)\n","            torch_layer_output_var.backward()\n","            torch_layer_grad_var = layer_input_var.grad\n","            self.assertTrue(np.allclose(torch_layer_grad_var.data.numpy(), custom_layer_grad, atol=1e-6))\n","\n","    def test_NLLCriterion(self):\n","        np.random.seed(RANDOM_SEED)\n","        torch.manual_seed(RANDOM_SEED)\n","        batch_size, n_in = 2, 4\n","        for _ in range(100):\n","            # инициализируем слои\n","            torch_layer = torch.nn.NLLLoss()\n","            custom_layer = NLLCriterion()\n","            # формируем тестовые данные\n","            layer_input = np.random.uniform(-5, 5, (batch_size, n_in)).astype(np.float32)\n","            layer_input = torch.nn.LogSoftmax(dim=1)(torch.from_numpy(layer_input)).data.numpy()\n","            target_labels = np.random.choice(n_in, batch_size)\n","            target = np.zeros((batch_size, n_in), np.float32)\n","            target[np.arange(batch_size), target_labels] = 1  # one-hot encoding\n","            # тестируем `update_output()`\n","            custom_layer_output = custom_layer.update_output(layer_input, target)\n","            layer_input_var = torch.from_numpy(layer_input)\n","            layer_input_var.requires_grad = True \n","            torch_layer_output_var = torch_layer(layer_input_var, torch.from_numpy(target_labels).long())\n","            self.assertTrue(np.allclose(\n","                torch_layer_output_var.data.numpy(), custom_layer_output, atol=1e-6\n","            ))\n","            # тестируем `update_grad_input()`\n","            custom_layer_grad = custom_layer.update_grad_input(layer_input, target)\n","            torch_layer_output_var.backward()\n","            torch_layer_grad_var = layer_input_var.grad\n","            self.assertTrue(np.allclose(torch_layer_grad_var.data.numpy(), custom_layer_grad, atol=1e-6))\n","            \n","    \n","suite = unittest.TestLoader().loadTestsFromTestCase(TestLayers)\n","unittest.TextTestRunner(verbosity=2).run(suite)"]},{"cell_type":"markdown","metadata":{"id":"1jDxUZRVIGB0"},"source":["---"]}],"metadata":{"colab":{"name":"[2.1]_test_modules.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":0}